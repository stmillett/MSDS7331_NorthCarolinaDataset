{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "<b>Class:</b> MSDS 7331 Data Mining\n",
    "<br> <b>Dataset:</b> Belk Endowment Educational Attainment Data \n",
    "\n",
    "<h1 style=\"font-size:150%;\"> Teammates </h1>\n",
    "Maryam Shahini\n",
    "<br> Murtada Shubbar\n",
    "<br> Michael Toolin\n",
    "<br> Steven Millett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set global variables\n",
    "#Number of features we will be selecting for feature selection\n",
    "\n",
    "N_FEATURES_OPTIONS = [2, 25 , 50]\n",
    "\n",
    "\n",
    "#Alpha and C we will be using for our classifiers\n",
    "\n",
    "C_OPTIONS = [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "\n",
    "\n",
    "#Import data all necessary libraries we will be using in our estimation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import sklearn\n",
    "import statistics\n",
    "\n",
    "\n",
    "from umap.umap_ import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, RFE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.a Data Preparation\n",
    "10 points - Deﬁne and prepare your class variables. Use proper variable \n",
    "representations (int, ﬂoat, one-hot, etc.). Use pre-processing methods (as needed) for\n",
    "dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for \n",
    "the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.b Data Preparation\n",
    "5 points - Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2017 Public Schools Machine Learning \n",
    "# Date Set is being used throughout this \n",
    "# analysis.  The _ML suffix is removed to less \n",
    "# name space size\n",
    "# Load Full Public School Data Frames for each year\n",
    "\n",
    "school_data_14 = pd.read_csv('../Data/2014/Machine Learning Datasets/PublicSchools2014_ML.csv', low_memory=False)\n",
    "school_data_15 = pd.read_csv('../Data/2015/Machine Learning Datasets/PublicSchools2015_ML.csv', low_memory=False)\n",
    "school_data_16 = pd.read_csv('../Data/2016/Machine Learning Datasets/PublicSchools2016_ML.csv', low_memory=False)\n",
    "school_data_17 = pd.read_csv('../Data/2017/Machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data = pd.concat([school_data_14, school_data_15, school_data_16, school_data_17],ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0-3 Years_LEA_Exp_Pct_Prin</th>\n",
       "      <th>00_Size</th>\n",
       "      <th>01_Size</th>\n",
       "      <th>02_Size</th>\n",
       "      <th>03_Size</th>\n",
       "      <th>04_Size</th>\n",
       "      <th>05_Size</th>\n",
       "      <th>10+ Years_LEA_Exp_Pct_Prin</th>\n",
       "      <th>4-10 Years_LEA_Exp_Pct_Prin</th>\n",
       "      <th>Accomplished_TCHR_Standard 1_Pct</th>\n",
       "      <th>...</th>\n",
       "      <th>st_tchyrs_11plus_pct</th>\n",
       "      <th>st_tchyrs_4thru10_pct</th>\n",
       "      <th>stud_internet_comp_num</th>\n",
       "      <th>student_num</th>\n",
       "      <th>tchyrs_0thru3_pct</th>\n",
       "      <th>tchyrs_11plus_pct</th>\n",
       "      <th>tchyrs_4thru10_pct</th>\n",
       "      <th>unit_code</th>\n",
       "      <th>wap_num</th>\n",
       "      <th>wap_per_classroom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.67</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.200</td>\n",
       "      <td>10303</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.11</td>\n",
       "      <td>539.0</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.353</td>\n",
       "      <td>10304</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.96</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.257</td>\n",
       "      <td>10308</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.99</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.327</td>\n",
       "      <td>10310</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.14</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.357</td>\n",
       "      <td>10312</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.43</td>\n",
       "      <td>330.0</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.222</td>\n",
       "      <td>10320</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.309</td>\n",
       "      <td>10324</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.54</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.381</td>\n",
       "      <td>10326</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.64</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.175</td>\n",
       "      <td>10328</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.611</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.20</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.262</td>\n",
       "      <td>10340</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0-3 Years_LEA_Exp_Pct_Prin  00_Size  01_Size  02_Size  03_Size  04_Size  \\\n",
       "0                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "1                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "2                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "3                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "4                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "5                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "6                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "7                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "8                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "9                       0.611     13.0     12.0     13.0     12.0     14.0   \n",
       "\n",
       "   05_Size  10+ Years_LEA_Exp_Pct_Prin  4-10 Years_LEA_Exp_Pct_Prin  \\\n",
       "0     12.0                       0.083                        0.306   \n",
       "1     12.0                       0.083                        0.306   \n",
       "2     12.0                       0.083                        0.306   \n",
       "3     12.0                       0.083                        0.306   \n",
       "4     12.0                       0.083                        0.306   \n",
       "5     12.0                       0.083                        0.306   \n",
       "6     12.0                       0.083                        0.306   \n",
       "7     12.0                       0.083                        0.306   \n",
       "8     12.0                       0.083                        0.306   \n",
       "9     12.0                       0.083                        0.306   \n",
       "\n",
       "   Accomplished_TCHR_Standard 1_Pct        ...          st_tchyrs_11plus_pct  \\\n",
       "0                             0.800        ...                         0.506   \n",
       "1                             0.467        ...                         0.506   \n",
       "2                             0.694        ...                         0.506   \n",
       "3                             0.517        ...                         0.506   \n",
       "4                             0.535        ...                         0.506   \n",
       "5                             0.462        ...                         0.506   \n",
       "6                             0.500        ...                         0.506   \n",
       "7                             0.556        ...                         0.506   \n",
       "8                             0.711        ...                         0.506   \n",
       "9                             0.700        ...                         0.506   \n",
       "\n",
       "   st_tchyrs_4thru10_pct  stud_internet_comp_num  student_num  \\\n",
       "0                  0.251                    0.67         78.0   \n",
       "1                  0.291                    2.11        539.0   \n",
       "2                  0.291                    1.96        547.0   \n",
       "3                  0.274                    0.99        800.0   \n",
       "4                  0.291                    2.14        664.0   \n",
       "5                  0.291                    1.43        330.0   \n",
       "6                  0.251                    1.95       1192.0   \n",
       "7                  0.291                    0.54        492.0   \n",
       "8                  0.291                    2.64        628.0   \n",
       "9                  0.291                    2.20        621.0   \n",
       "\n",
       "   tchyrs_0thru3_pct  tchyrs_11plus_pct  tchyrs_4thru10_pct  unit_code  \\\n",
       "0              0.000              0.800               0.200      10303   \n",
       "1              0.206              0.441               0.353      10304   \n",
       "2              0.057              0.686               0.257      10308   \n",
       "3              0.269              0.404               0.327      10310   \n",
       "4              0.310              0.333               0.357      10312   \n",
       "5              0.222              0.556               0.222      10320   \n",
       "6              0.176              0.515               0.309      10324   \n",
       "7              0.381              0.238               0.381      10326   \n",
       "8              0.250              0.575               0.175      10328   \n",
       "9              0.238              0.500               0.262      10340   \n",
       "\n",
       "   wap_num  wap_per_classroom  \n",
       "0     42.0               1.17  \n",
       "1     42.0               1.17  \n",
       "2     42.0               1.17  \n",
       "3     42.0               1.17  \n",
       "4     42.0               1.17  \n",
       "5     42.0               1.17  \n",
       "6     42.0               1.17  \n",
       "7     42.0               1.17  \n",
       "8     42.0               1.17  \n",
       "9     42.0               1.17  \n",
       "\n",
       "[10 rows x 433 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the critical threshold\n",
    "CRITICAL_NA = .75\n",
    "\n",
    "#With this we check if the column is less than 75% non-NA, if it is greater than 75% non-NA\n",
    "#We replace the NA with the median of the column, otherwise we replace the value with 0\n",
    "\n",
    "imputed_school_data = school_data.apply(lambda col: col.fillna(0) if col.count()/col.shape[0]<CRITICAL_NA else col.fillna(col.median()),axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a Modeling and Evaluation\n",
    "10 points - Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b Modeling and Evaluation\n",
    "10 points - Choose the method you will use for dividing your data into training and why testing splits (i.e., are you using Stratiﬁed 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into X and y dataframes\n",
    "\n",
    "SPG_Grade_col = imputed_school_data.filter(regex=('^SPG\\WGrade')).columns\n",
    "imputed_school_data[SPG_Grade_col] = imputed_school_data[SPG_Grade_col].apply(lambda col: col.astype(int), axis=1)\n",
    "y = imputed_school_data[SPG_Grade_col].apply(lambda row:'A' if row.any()!=1 else row[0]*'A+NG'+row[1]*'B'+row[2]*'C'+row[3]*'D'+row[4]*'F'+row[5]*'I',axis=1)\n",
    "\n",
    "#Removed SPG Grade and unit code(which is primary key for school data table)\n",
    " \n",
    "X = imputed_school_data[school_data.columns.drop(list(school_data.filter(regex='^SPG\\WGrade|^SPG\\WScore|unit_code')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into test and train sets. We still want\n",
    "# to do this for external Cross Validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c Modeling and Evaluation\n",
    "20 points - Create three different classification/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. 'TSNE(angle=0.5, early_exaggeration=12.0, init='random', learning_rate=200.0,\n   method='barnes_hut', metric='euclidean', min_grad_norm=1e-07,\n   n_components=2, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0)' (type <class 'sklearn.manifold.t_sne.TSNE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-23ee5e7e1383>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m pipe = Pipeline([('reduce_dim', TSNE(n_components=2)),\n\u001b[0;32m     14\u001b[0m                   \u001b[1;33m(\u001b[0m\u001b[1;34m'scale'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                   ('clf', LogisticRegression())])\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, steps, memory)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[0;32m    161\u001b[0m                                 \u001b[1;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. 'TSNE(angle=0.5, early_exaggeration=12.0, init='random', learning_rate=200.0,\n   method='barnes_hut', metric='euclidean', min_grad_norm=1e-07,\n   n_components=2, n_iter=1000, n_iter_without_progress=300,\n   perplexity=30.0, random_state=None, verbose=0)' (type <class 'sklearn.manifold.t_sne.TSNE'>) doesn't"
     ]
    }
   ],
   "source": [
    "# Here we establish a basic 10 k-fold internal\n",
    "# Cross Validation seperation that will be used\n",
    "# for training our model.\n",
    "\n",
    "k_fold = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#This creates the template for the pipeline\n",
    "# This creates a basic pipeline where we will \n",
    "# test for dementionality reduction, scaling,\n",
    "# and classification.\n",
    "\n",
    "X_train = TSNE(n_components=2).fit_transform(X_train)\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', TSNE(n_components=2)),\n",
    "                  ('scale', StandardScaler()), \n",
    "                  ('clf', LogisticRegression())])\n",
    "\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-6e99d4e0617e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    195\u001b[0m                                 if step is not None)\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m             \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Don't run this unless you want to retrain the data.\n",
    "\n",
    "# # Here we are establishing the basic testing criteria\n",
    "# # for our pipeline. This will run through a number of\n",
    "# # parameters for our pipeline, including type of dimensionality\n",
    "# # reduction, number of features to reduce, scaling (yes/no), \n",
    "# # classification models, and parameters of the classification model.\n",
    "\n",
    "# param_grid = [\n",
    "#     {\n",
    "#         'reduce_dim': [NMF(), PCA(),TSNE()],\n",
    "#         'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "#         'scale':[None,StandardScaler()],\n",
    "#         'clf':[SVC(),LogisticRegression()],\n",
    "#         'clf__C': C_OPTIONS\n",
    "#     },\n",
    "#     {\n",
    "#         'reduce_dim': [NMF(), PCA(),TSNE()],\n",
    "#         'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "#         'scale':[None,StandardScaler()],\n",
    "#         'clf':[SGDClassifier(tol=1e-3,max_iter=1000)],\n",
    "#         'clf__alpha': C_OPTIONS\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "# grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# #This saves the grid_search variable\n",
    "# # to an external file so we don't have to \n",
    "# # keep running the gridsearch\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(grid_search, 'savedBestModel.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d Modeling and Evaluation\n",
    "10 points - Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to load the model from the save file\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "grid_search = joblib.load('savedBestModel.pkl')\n",
    "\n",
    "\n",
    "# Loads all parameters run into a dict \n",
    "\n",
    "params = np.array(grid_search.cv_results_['params'])\n",
    "\n",
    "\n",
    "# Loads all mean test scores into an array\n",
    "\n",
    "mean_scores = np.array(grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.0001",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2183005e9215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf__C'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'clf__C'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf__alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mclass_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mclassifier_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mclassifier_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2536\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2537\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0.0001"
     ]
    }
   ],
   "source": [
    "# Assigns all models to an array\n",
    "\n",
    "classifier_labels=['SVC','LogisticRegression','SGDClassifier']\n",
    "\n",
    "\n",
    "# Creates an empty dataframe that is to be\n",
    "# filled with the mean test accuracy by C global\n",
    "# variable and the different classifiers\n",
    "\n",
    "classifier_temp = pd.DataFrame(columns=classifier_labels,index=C_OPTIONS,\n",
    "                               data=np.linspace(.1,.25,num=len(C_OPTIONS)*len(classifier_labels)).reshape(len(C_OPTIONS),len(classifier_labels)))\n",
    "classifier_temp.fillna(0,inplace=True)\n",
    "\n",
    "for i, (param, score) in enumerate(zip(params, mean_scores)):\n",
    "    C = param['clf__C'] if 'clf__C' in param else param['clf__alpha']\n",
    "    class_state = str(param['clf']).split('(')[0]\n",
    "    if classifier_temp.at[C,class_state] < score:\n",
    "        classifier_temp.at[C,class_state] = score\n",
    "\n",
    "\n",
    "# Printing a grid of the best accuracies\n",
    "        \n",
    "display(classifier_temp.transpose())   \n",
    "\n",
    "\n",
    "# Print a line plot which shows the best \n",
    "# accuracies\n",
    " \n",
    "classifier_temp.plot(logx=True,ylim=(0,1),figsize=(14,10),title='Accuracy by Classifier'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'100'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8156aaed1bf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mreduce_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SelectKBest'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtrigger\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_FEAT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mreduce_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_FEAT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_state\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2536\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2537\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '100'"
     ]
    }
   ],
   "source": [
    "# Assigns all reduction models to an array\n",
    "\n",
    "reduce_labels=['NMF','PCA','SelectKBest']\n",
    "\n",
    "\n",
    "# Translates the N Features array\n",
    "# to an array full of string\n",
    "\n",
    "temp_N_FEATURES_OPTIONS = [str(r) for r in N_FEATURES_OPTIONS]\n",
    "temp_N_FEATURES_OPTIONS=temp_N_FEATURES_OPTIONS+['None']\n",
    "\n",
    "\n",
    "# Creates an empty dataframe that is to be\n",
    "# filled with the mean test accuracy by N Features\n",
    "# variable and the different feature reduction models\n",
    "\n",
    "reduce_temp = pd.DataFrame(columns=reduce_labels,index=temp_N_FEATURES_OPTIONS,\n",
    "                               data=np.linspace(.1,.25,num=len(temp_N_FEATURES_OPTIONS)*len(reduce_labels)).reshape(+len(temp_N_FEATURES_OPTIONS),len(reduce_labels)))\n",
    "\n",
    "\n",
    "for i, (param, score) in enumerate(zip(params, mean_scores)):\n",
    "    trigger=0\n",
    "    reduce_state = str(param['reduce_dim']).split('(')[0]\n",
    "    if 'reduce_dim__k' in param:\n",
    "        N_FEAT = str(param['reduce_dim__k'])\n",
    "        trigger=1\n",
    "    elif 'reduce_dim__n_components' in param:\n",
    "        N_FEAT = str(param['reduce_dim__n_components'])\n",
    "        trigger=1\n",
    "    else:\n",
    "        if reduce_temp.at['None','NMF'] < score:\n",
    "            reduce_temp.at['None','NMF'] = score\n",
    "            reduce_temp.at['None','SelectKBest'] = score\n",
    "    if trigger == 1:\n",
    "        if reduce_temp.at[N_FEAT,reduce_state] < score:\n",
    "            reduce_temp.at[N_FEAT,reduce_state] = score\n",
    "\n",
    "            \n",
    "# Printing a grid of the best accuracies\n",
    "\n",
    "display(reduce_temp.transpose())\n",
    "\n",
    "\n",
    "# Print a bar plot which shows the best \n",
    "# accuracies\n",
    "\n",
    "reduce_temp.plot(kind='bar',ylim=(0,1),figsize=(14,10),title='Accuracy by Feature Selection',rot=0);           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Index of the best model is',grid_search.best_index_)\n",
    "print('The parameters of the best model is')\n",
    "display(grid_search.best_params_)\n",
    "print('The accuracy of the best model is',round(grid_search.best_score_*100,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e Modeling and Evaluation\n",
    "10 points - Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference signiﬁcant with 95% conﬁdence? Use proper statistical comparison methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.f Modeling and Evaluation\n",
    "10 points - Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classiﬁcation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "5 points - How useful is yolur model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "10 points - You have free reign to provide additional modeling. \n",
    "One idea: grid search parameters in a parallelized fashion and visualize the \n",
    "performances across attributes. Which parameters are most signiﬁcant for making a \n",
    "good model for each classiﬁcation algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
