{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "\n",
    "<b>Class:</b> MSDS 7331 Data Mining\n",
    "<br> <b>Dataset:</b> Belk Endowment Educational Attainment Data \n",
    "\n",
    "<h1 style=\"font-size:150%;\"> Teammates </h1>\n",
    "Maryam Shahini\n",
    "<br> Murtada Shubbar\n",
    "<br> Michael Toolin\n",
    "<br> Steven Millett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set global variables\n",
    "#Variables for file and school informaiton\n",
    "\n",
    "YEARS = ['2014', '2015', '2016', '2017']\n",
    "SCHOOLS = ['High','Middle','Elementary']\n",
    "\n",
    "#Number of features we will be selecting for feature selection\n",
    "\n",
    "N_FEATURES_OPTIONS = [2, 25 , 50]\n",
    "\n",
    "#Alpha and C we will be using for our classifiers\n",
    "\n",
    "C_OPTIONS = [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "\n",
    "#Import data all necessary libraries we will be using in our estimation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import sklearn\n",
    "import statistics\n",
    "\n",
    "\n",
    "#from umap.umap_ import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile, RFE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.a Data Preparation\n",
    "10 points - Deﬁne and prepare your class variables. Use proper variable \n",
    "representations (int, ﬂoat, one-hot, etc.). Use pre-processing methods (as needed) for\n",
    "dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for \n",
    "the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.b Data Preparation\n",
    "5 points - Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2017 Public Schools Machine Learning \n",
    "# Date Set is being used throughout this \n",
    "# analysis.  The _ML suffix is removed to less \n",
    "# name space size\n",
    "# Load Full Public School Data Frames for each year\n",
    "\n",
    "school_data = pd.DataFrame()\n",
    "\n",
    "for year in YEARS:\n",
    "    #Load public school master file\n",
    "    temp_year = pd.read_csv('../Data/'+str(year)+'/Machine Learning Datasets/PublicSchools'+str(year)+'_ML.csv', low_memory=False)\n",
    "    \n",
    "    #Iterate through adding and merging school data based on school type\n",
    "    for grade in SCHOOLS:\n",
    "        grade_temp_year = pd.read_csv('../Data/'+year+'/Machine Learning Datasets/Public'+grade+'Schools'+year+'_ML.csv', low_memory=False)\n",
    "        cols_to_use = grade_temp_year.columns.difference(temp_year.columns)\n",
    "        cols_to_use = np.append(cols_to_use,'unit_code')\n",
    "        temp_year = pd.merge(temp_year, grade_temp_year[cols_to_use],left_index=True, right_index=True, on='unit_code',how='left' )\n",
    "    \n",
    "    #Add year column and concatonating all data together\n",
    "    temp_year['Year']=year\n",
    "    school_data = pd.concat([school_data,temp_year],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the critical threshold\n",
    "CRITICAL_NA = .75\n",
    "\n",
    "#With this we check if the column is less than 75% non-NA, if it is greater than 75% non-NA\n",
    "#We replace the NA with the median of the column, otherwise we replace the value with 0\n",
    "\n",
    "imputed_school_data = school_data.apply(lambda col: col.fillna(0) if col.count()/col.shape[0]<CRITICAL_NA else col.fillna(col.median()),axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GraduationRate_5yr_Female', 'Math Course Rigor Score', 'lea_highqual_class_all_pct', 'lea_highqual_class_pct', 'st_highqual_class_pct', 'st_total_specialized_courses']\n"
     ]
    }
   ],
   "source": [
    "# corr_matrix = imputed_school_data.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
    "\n",
    "# print(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.a Modeling and Evaluation\n",
    "Using the right evaluation metric for classification system is crucial. Otherwise, it may results in thinking that the model is performing well but in reality, it doesn’t.\n",
    "\n",
    "There are two tasks in this section of “NC Educational Data” project:\n",
    "\n",
    "The first task is to predict a binary classification target, either if the average SAT score of each school is good enough to gets the student to the North Carolina Universities or not. The SAT is a standardized test widely used for college admissions in the United States. For this purpose we have a cut off 1200 out of 1600. The second task is to predict if the crime per 100 students at each school level is higher than the LEA level or not. After considering all evaluation metrics for classification systems, we ended up using ROC Curve. Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems.\n",
    "\n",
    "In fact, a ROC curve can be used to select a threshold for a classifier which maximizes the true positives, while minimizing the false positives.\n",
    "\n",
    "We usually use ROC when both classes detection are important. Here, our models should be able to decrease both false positive rate (which is identifying the schools with enough good average SAT score for getting admission in different universities) and also decreasing the false negative rate (which is detecting schools with not good average SAT scores).\n",
    "\n",
    "The same for the second task, it is important to decrease both false positive and false negative rates.\n",
    "\n",
    "The AUC represents a model’s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random. Most classifiers have AUCs that fall somewhere between these two values. Therefore, the overall model performances can be compared by considering the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b Modeling and Evaluation\n",
    "10 points - Choose the method you will use for dividing your data into training and why testing splits (i.e., are you using Stratiﬁed 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into test and train sets. We still want\n",
    "# to do this for external Cross Validation\n",
    "\n",
    "crime_imputed_school_data = imputed_school_data\n",
    "\n",
    "crime_imputed_school_data['local_crime_greater'] = crime_imputed_school_data.apply(lambda each_row: 1 if (each_row['crime_per_c_num']-each_row['lea_crime_per_c_num'])<0 else 0,axis=1)\n",
    "\n",
    "#split data into X and y dataframes\n",
    "\n",
    "y_crime = crime_imputed_school_data['local_crime_greater']\n",
    "\n",
    "#Removed SPG Grade and unit code(which is primary key for school data table)\n",
    " \n",
    "X_crime = imputed_school_data[school_data.columns.drop(list(school_data.filter(regex='crime|unit_code|lea|LEA|^st\\_')))]\n",
    "\n",
    "X_crime_train, X_crime_test, y_crime_train, y_crime_test = train_test_split(X_crime, y_crime, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c Modeling and Evaluation\n",
    "20 points - Create three different classification/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#This creates the template for the pipeline\n",
    "# This creates a basic pipeline where we will \n",
    "# test for dementionality reduction, scaling,\n",
    "# and classification.\n",
    "\n",
    "\n",
    "pipe = Pipeline([ ('reduce_dim',SelectKBest(chi2)),\n",
    "                  ('scale', StandardScaler()), \n",
    "                  ('clf', GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7043625376861664\n"
     ]
    }
   ],
   "source": [
    " param_grid = [\n",
    "    {\n",
    "         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "         'clf__n_estimators': C_ESTIMATORS, \n",
    "         'clf__max_depth': C_DEPTH,\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "crime_GradientBoost_model = grid_search.fit(X_crime_train, y_crime_train)\n",
    "\n",
    "\n",
    "y_crime_score = grid_search.predict(X_crime_test)\n",
    "\n",
    "print(roc_auc_score(y_crime_test, y_crime_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', SelectKBest(k='all', score_func=<function chi2 at 0x7ff484499620>)), ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=5, ma...rs=50, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(**crime_GradientBoost_model.best_params_)\n",
    "pipe.fit(X_crime_train, y_crime_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 features that influence SPG Grade are the following\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Influence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>short_susp_per_c_num</th>\n",
       "      <td>0.089424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_daily_attend_pct</th>\n",
       "      <td>0.024873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPG Score</th>\n",
       "      <td>0.019061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoOrMorePct</th>\n",
       "      <td>0.017637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlackFemalePct</th>\n",
       "      <td>0.017281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_All</th>\n",
       "      <td>0.016024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_Hispanic</th>\n",
       "      <td>0.015840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books_per_student</th>\n",
       "      <td>0.013949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_White</th>\n",
       "      <td>0.013150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOGScienceGr8_GLP_SWD</th>\n",
       "      <td>0.011988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_susp_per_c_num</th>\n",
       "      <td>0.011965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlackMalePct</th>\n",
       "      <td>0.011592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_Black</th>\n",
       "      <td>0.011327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MinorityMalePct</th>\n",
       "      <td>0.010561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVAAS Growth Score</th>\n",
       "      <td>0.010119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proficient_TCHR_Standard 2_Pct</th>\n",
       "      <td>0.009211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_1yr_tchr_trnovr_pct</th>\n",
       "      <td>0.009054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IndianFemalePct</th>\n",
       "      <td>0.008498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_num</th>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advance_dgr_pct</th>\n",
       "      <td>0.007695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Influence\n",
       "short_susp_per_c_num             0.089424\n",
       "avg_daily_attend_pct             0.024873\n",
       "SPG Score                        0.019061\n",
       "TwoOrMorePct                     0.017637\n",
       "BlackFemalePct                   0.017281\n",
       "EOG/EOCSubjects_CACR_All         0.016024\n",
       "EOG/EOCSubjects_CACR_Hispanic    0.015840\n",
       "books_per_student                0.013949\n",
       "EOG/EOCSubjects_CACR_White       0.013150\n",
       "EOGScienceGr8_GLP_SWD            0.011988\n",
       "long_susp_per_c_num              0.011965\n",
       "BlackMalePct                     0.011592\n",
       "EOG/EOCSubjects_CACR_Black       0.011327\n",
       "MinorityMalePct                  0.010561\n",
       "EVAAS Growth Score               0.010119\n",
       "Proficient_TCHR_Standard 2_Pct   0.009211\n",
       "_1yr_tchr_trnovr_pct             0.009054\n",
       "IndianFemalePct                  0.008498\n",
       "student_num                      0.008002\n",
       "advance_dgr_pct                  0.007695"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = pipe.steps[2][1].feature_importances_\n",
    "\n",
    "mask = pipe.steps[0][1].get_support()\n",
    "new_features=[]\n",
    "feature_names=list(X_crime_train.columns.values)\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "\n",
    "#Creates a new dataframe with the coefficients and the \n",
    "predicted_data = pd.DataFrame(data=coef,index=new_features,columns=['Influence'])\n",
    "print(\"The top 20 features that influence SPG Grade are the following\")\n",
    "\n",
    "\n",
    "\n",
    "display(predicted_data.sort_values(by='Influence', ascending=False)[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6369818484422948\n"
     ]
    }
   ],
   "source": [
    " param_grid = [\n",
    "    {\n",
    "         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "         'clf': [AdaBoostClassifier()],\n",
    "         'clf__n_estimators': C_ESTIMATORS\n",
    "\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "crime_ADABoost_model = grid_search.fit(X_crime_train, y_crime_train)\n",
    "\n",
    "y_crime_score = grid_search.predict(X_crime_test)\n",
    "\n",
    "print(roc_auc_score(y_crime_test, y_crime_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None), 'clf__n_estimators': 50, 'reduce_dim__k': 'all'}\n"
     ]
    }
   ],
   "source": [
    "print(crime_ADABoost_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   58.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6155341446923598\n"
     ]
    }
   ],
   "source": [
    " param_grid = [\n",
    "    {\n",
    "         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "         'clf': [RandomForestClassifier()],\n",
    "         'clf__n_estimators': C_ESTIMATORS, \n",
    "         'clf__max_depth': C_DEPTH,\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "crime_RandomForest_model = grid_search.fit(X_crime_train, y_crime_train)\n",
    "\n",
    "y_crime_score = grid_search.predict(X_crime_test)\n",
    "\n",
    "print(roc_auc_score(y_crime_test, y_crime_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'clf__max_depth': 5, 'clf__n_estimators': 50, 'reduce_dim__k': 'all'}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(crime_RandomForest_model.best_params_)\n",
    "print(crime_RandomForest_model.multimetric_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 10.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6263636422738856\n"
     ]
    }
   ],
   "source": [
    " param_grid = [\n",
    "    {\n",
    "         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "         'clf': [KNeighborsClassifier()],\n",
    "         'clf__n_neighbors': C_NEIGHBORS, \n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "crime_KNearest_model = grid_search.fit(X_crime_train, y_crime_train)\n",
    "\n",
    "y_crime_score = grid_search.predict(X_crime_test)\n",
    "\n",
    "print(roc_auc_score(y_crime_test, y_crime_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=40, p=2,\n",
      "           weights='uniform'), 'clf__n_neighbors': 40, 'reduce_dim__k': 100}\n"
     ]
    }
   ],
   "source": [
    "print(crime_KNearest_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced scope model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crime_reduced = X_crime[X_crime.columns.drop(list(X_crime.filter(regex='[Aa]sian|[Hh]ispanic|[Rr]ace|[Bb]lack|[Mm]inority|[Tw]wo[Oo]r[Mm]ore|[Ii]ndian|[Ww]hite')))]\n",
    "X_crime_reduced_train, X_crime_reduced_test, y_crime_reduced_train, y_crime_reduced_test = train_test_split(X_crime_reduced, y_crime, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00_Size' '01_Size' '02_Size' '03_Size' '04_Size' '05_Size' '06_Size'\n",
      " '07_Size' '08_Size' '09_Size' '10_Size' '11_Size' '12_Size'\n",
      " '4-Year Cohort Graduation Rate Score' 'AAVC_Concentrator_Ct' 'ACT Score'\n",
      " 'ACT WorkKeys Score' 'ACTCompositeScore_UNCMin_AIG'\n",
      " 'ACTCompositeScore_UNCMin_EDS' 'ACTCompositeScore_UNCMin_Female'\n",
      " 'ACTCompositeScore_UNCMin_LEP' 'ACTCompositeScore_UNCMin_Male'\n",
      " 'ACTCompositeScore_UNCMin_SWD' 'ACTEnglish_ACTBenchmark_AIG'\n",
      " 'ACTEnglish_ACTBenchmark_EDS' 'ACTEnglish_ACTBenchmark_Female'\n",
      " 'ACTEnglish_ACTBenchmark_LEP' 'ACTEnglish_ACTBenchmark_Male'\n",
      " 'ACTEnglish_ACTBenchmark_SWD' 'ACTMath_ACTBenchmark_AIG'\n",
      " 'ACTMath_ACTBenchmark_All' 'ACTMath_ACTBenchmark_EDS'\n",
      " 'ACTMath_ACTBenchmark_Female' 'ACTMath_ACTBenchmark_LEP'\n",
      " 'ACTMath_ACTBenchmark_Male' 'ACTMath_ACTBenchmark_SWD'\n",
      " 'ACTReading_ACTBenchmark_AIG' 'ACTReading_ACTBenchmark_All'\n",
      " 'ACTReading_ACTBenchmark_EDS' 'ACTReading_ACTBenchmark_Female'\n",
      " 'ACTReading_ACTBenchmark_LEP' 'ACTReading_ACTBenchmark_Male'\n",
      " 'ACTReading_ACTBenchmark_SWD' 'ACTScience_ACTBenchmark_AIG'\n",
      " 'ACTScience_ACTBenchmark_All' 'ACTScience_ACTBenchmark_EDS'\n",
      " 'ACTScience_ACTBenchmark_Female' 'ACTScience_ACTBenchmark_LEP'\n",
      " 'ACTScience_ACTBenchmark_Male' 'ACTScience_ACTBenchmark_SWD'\n",
      " 'ACTSubtests_BenchmarksMet_AIG' 'ACTSubtests_BenchmarksMet_EDS'\n",
      " 'ACTSubtests_BenchmarksMet_LEP' 'ACTSubtests_BenchmarksMet_Male'\n",
      " 'ACTSubtests_BenchmarksMet_SWD' 'ACTWorkKeys_SilverPlus_AIG'\n",
      " 'ACTWorkKeys_SilverPlus_All' 'ACTWorkKeys_SilverPlus_EDS'\n",
      " 'ACTWorkKeys_SilverPlus_Female' 'ACTWorkKeys_SilverPlus_LEP'\n",
      " 'ACTWorkKeys_SilverPlus_Male' 'ACTWorkKeys_SilverPlus_SWD'\n",
      " 'ACTWorkKeys_pTarget_PctMet' 'ACTWriting_ACTBenchmark_AIG'\n",
      " 'ACTWriting_ACTBenchmark_All' 'ACTWriting_ACTBenchmark_EDS'\n",
      " 'ACTWriting_ACTBenchmark_LEP' 'ACTWriting_ACTBenchmark_Male'\n",
      " 'ACTWriting_ACTBenchmark_SWD' 'ACT_pTarget_PctMet' 'AGNR_Concentrator_Ct'\n",
      " 'ALL_All Students (Total or Subtotal_ENROLL_sch_pct'\n",
      " 'ARCH_Concentrator_Ct' 'Accomplished_TCHR_Standard 1_Pct'\n",
      " 'Accomplished_TCHR_Standard 2_Pct' 'Accomplished_TCHR_Standard 3_Pct'\n",
      " 'Accomplished_TCHR_Standard 4_Pct' 'Accomplished_TCHR_Standard 5_Pct'\n",
      " 'All_All Student (Total or subtotal)_ENROLL_sch_pct'\n",
      " 'BMA_Concentrator_Ct' 'Biology Score' 'Biology_Size' 'Byod_No' 'Byod_YES'\n",
      " 'Byod_Yes' 'Category_Cd_H' 'Cohort Graduation Rate Standard Score'\n",
      " 'CurrentYearEOC_pTarget_PctMet' 'Developing_TCHR_Standard 1_Pct'\n",
      " 'Developing_TCHR_Standard 2_Pct' 'Developing_TCHR_Standard 3_Pct'\n",
      " 'Developing_TCHR_Standard 4_Pct' 'Developing_TCHR_Standard 5_Pct'\n",
      " 'Distinguished_TCHR_Standard 1_Pct' 'Distinguished_TCHR_Standard 2_Pct'\n",
      " 'Distinguished_TCHR_Standard 3_Pct' 'Distinguished_TCHR_Standard 4_Pct'\n",
      " 'Distinguished_TCHR_Standard 5_Pct'\n",
      " 'Does Not Meet Expected Growth_TCHR_Standard 6_Pct'\n",
      " 'Does Not Meet Expected Growth_TCHR_Student Growth_Pct'\n",
      " 'ECODIS_Economically Disadvantaged_ENROLL_sch_pct' 'EOCBiology_CACR_AIG'\n",
      " 'EOCBiology_CACR_EDS' 'EOCBiology_CACR_Female' 'EOCBiology_CACR_LEP'\n",
      " 'EOCBiology_CACR_Male' 'EOCBiology_CACR_SWD' 'EOCBiology_GLP_LEP'\n",
      " 'EOCBiology_GLP_SWD' 'EOCEnglish2_CACR_AIG' 'EOCEnglish2_CACR_EDS'\n",
      " 'EOCEnglish2_CACR_Female' 'EOCEnglish2_CACR_LEP' 'EOCEnglish2_CACR_Male'\n",
      " 'EOCEnglish2_CACR_SWD' 'EOCEnglish2_GLP_LEP' 'EOCEnglish2_GLP_SWD'\n",
      " 'EOCMathI_CACR_AIG' 'EOCMathI_CACR_All' 'EOCMathI_CACR_EDS'\n",
      " 'EOCMathI_CACR_Female' 'EOCMathI_CACR_LEP' 'EOCMathI_CACR_Male'\n",
      " 'EOCMathI_CACR_SWD' 'EOCMathI_GLP_LEP' 'EOCMathI_GLP_SWD'\n",
      " 'EOCSubjects_CACR_AIG' 'EOCSubjects_CACR_All' 'EOCSubjects_CACR_EDS'\n",
      " 'EOCSubjects_CACR_Female' 'EOCSubjects_CACR_LEP' 'EOCSubjects_CACR_Male'\n",
      " 'EOCSubjects_CACR_SWD' 'EOCSubjects_GLP_LEP' 'EOCSubjects_GLP_SWD'\n",
      " 'EOG/EOCSubjects_CACR_AIG' 'EOG/EOCSubjects_CACR_All'\n",
      " 'EOG/EOCSubjects_CACR_EDS' 'EOG/EOCSubjects_CACR_LEP'\n",
      " 'EOG/EOCSubjects_CACR_SWD' 'EOG/EOCSubjects_GLP_AIG'\n",
      " 'EOG/EOCSubjects_GLP_LEP' 'EOG/EOCSubjects_GLP_SWD' 'EOGGr3_CACR_AIG'\n",
      " 'EOGGr3_CACR_All' 'EOGGr3_CACR_EDS' 'EOGGr3_CACR_LEP' 'EOGGr3_CACR_SWD'\n",
      " 'EOGGr3_GLP_LEP' 'EOGGr3_GLP_SWD' 'EOGGr4_CACR_AIG' 'EOGGr4_CACR_All'\n",
      " 'EOGGr4_CACR_EDS' 'EOGGr4_CACR_Female' 'EOGGr4_CACR_LEP'\n",
      " 'EOGGr4_CACR_SWD' 'EOGGr4_GLP_LEP' 'EOGGr4_GLP_SWD' 'EOGGr5_CACR_AIG'\n",
      " 'EOGGr5_CACR_All' 'EOGGr5_CACR_EDS' 'EOGGr5_CACR_LEP' 'EOGGr5_CACR_SWD'\n",
      " 'EOGGr5_GLP_LEP' 'EOGGr5_GLP_SWD' 'EOGGr6_CACR_AIG' 'EOGGr6_CACR_All'\n",
      " 'EOGGr6_CACR_EDS' 'EOGGr6_CACR_Female' 'EOGGr6_CACR_LEP'\n",
      " 'EOGGr6_CACR_Male' 'EOGGr6_CACR_SWD' 'EOGGr6_GLP_LEP' 'EOGGr6_GLP_SWD'\n",
      " 'EOGGr7_CACR_AIG' 'EOGGr7_CACR_All' 'EOGGr7_CACR_EDS'\n",
      " 'EOGGr7_CACR_Female' 'EOGGr7_CACR_LEP' 'EOGGr7_CACR_Male'\n",
      " 'EOGGr7_CACR_SWD' 'EOGGr7_GLP_LEP' 'EOGGr7_GLP_SWD' 'EOGGr8_CACR_AIG'\n",
      " 'EOGGr8_CACR_All' 'EOGGr8_CACR_EDS' 'EOGGr8_CACR_LEP' 'EOGGr8_CACR_SWD'\n",
      " 'EOGGr8_GLP_LEP' 'EOGGr8_GLP_SWD' 'EOGMathGr3-8_CACR_AIG'\n",
      " 'EOGMathGr3-8_CACR_EDS' 'EOGMathGr3-8_CACR_LEP' 'EOGMathGr3-8_CACR_SWD'\n",
      " 'EOGMathGr3-8_GLP_LEP' 'EOGMathGr3-8_GLP_SWD' 'EOGMathGr3_CACR_AIG'\n",
      " 'EOGMathGr3_CACR_EDS' 'EOGMathGr3_CACR_Female' 'EOGMathGr3_CACR_LEP'\n",
      " 'EOGMathGr3_CACR_Male' 'EOGMathGr3_CACR_SWD' 'EOGMathGr3_GLP_EDS'\n",
      " 'EOGMathGr3_GLP_Female' 'EOGMathGr3_GLP_LEP' 'EOGMathGr3_GLP_SWD'\n",
      " 'EOGMathGr4_CACR_AIG' 'EOGMathGr4_CACR_EDS' 'EOGMathGr4_CACR_Female'\n",
      " 'EOGMathGr4_CACR_LEP' 'EOGMathGr4_CACR_Male' 'EOGMathGr4_CACR_SWD'\n",
      " 'EOGMathGr4_GLP_LEP' 'EOGMathGr4_GLP_SWD' 'EOGMathGr5_CACR_AIG'\n",
      " 'EOGMathGr5_CACR_EDS' 'EOGMathGr5_CACR_Female' 'EOGMathGr5_CACR_LEP'\n",
      " 'EOGMathGr5_CACR_Male' 'EOGMathGr5_CACR_SWD' 'EOGMathGr5_GLP_LEP'\n",
      " 'EOGMathGr5_GLP_SWD' 'EOGMathGr6_CACR_AIG' 'EOGMathGr6_CACR_EDS'\n",
      " 'EOGMathGr6_CACR_Female' 'EOGMathGr6_CACR_LEP' 'EOGMathGr6_CACR_Male'\n",
      " 'EOGMathGr6_CACR_SWD' 'EOGMathGr6_GLP_LEP' 'EOGMathGr6_GLP_SWD'\n",
      " 'EOGMathGr7_CACR_AIG' 'EOGMathGr7_CACR_EDS' 'EOGMathGr7_CACR_Female'\n",
      " 'EOGMathGr7_CACR_LEP' 'EOGMathGr7_CACR_Male' 'EOGMathGr7_CACR_SWD'\n",
      " 'EOGMathGr7_GLP_LEP' 'EOGMathGr7_GLP_SWD' 'EOGMathGr8_CACR_AIG'\n",
      " 'EOGMathGr8_CACR_All' 'EOGMathGr8_CACR_EDS' 'EOGMathGr8_CACR_Female'\n",
      " 'EOGMathGr8_CACR_LEP' 'EOGMathGr8_CACR_Male' 'EOGMathGr8_CACR_SWD'\n",
      " 'EOGMathGr8_GLP_LEP' 'EOGMathGr8_GLP_SWD' 'EOGReadingGr3-8_CACR_AIG'\n",
      " 'EOGReadingGr3-8_CACR_EDS' 'EOGReadingGr3-8_CACR_LEP'\n",
      " 'EOGReadingGr3-8_CACR_SWD' 'EOGReadingGr3-8_GLP_LEP'\n",
      " 'EOGReadingGr3-8_GLP_SWD' 'EOGReadingGr3_CACR_EDS'\n",
      " 'EOGReadingGr3_CACR_Female' 'EOGReadingGr3_CACR_LEP'\n",
      " 'EOGReadingGr3_CACR_Male' 'EOGReadingGr3_CACR_SWD'\n",
      " 'EOGReadingGr3_GLP_EDS' 'EOGReadingGr3_GLP_Female'\n",
      " 'EOGReadingGr3_GLP_LEP' 'EOGReadingGr3_GLP_SWD' 'EOGReadingGr4_CACR_EDS'\n",
      " 'EOGReadingGr4_CACR_Female' 'EOGReadingGr4_CACR_LEP'\n",
      " 'EOGReadingGr4_CACR_Male' 'EOGReadingGr4_CACR_SWD'\n",
      " 'EOGReadingGr4_GLP_EDS' 'EOGReadingGr4_GLP_Female'\n",
      " 'EOGReadingGr4_GLP_LEP' 'EOGReadingGr4_GLP_Male' 'EOGReadingGr4_GLP_SWD'\n",
      " 'EOGReadingGr5_CACR_All' 'EOGReadingGr5_CACR_EDS'\n",
      " 'EOGReadingGr5_CACR_Female' 'EOGReadingGr5_CACR_LEP'\n",
      " 'EOGReadingGr5_CACR_Male' 'EOGReadingGr5_CACR_SWD'\n",
      " 'EOGReadingGr5_GLP_EDS' 'EOGReadingGr5_GLP_LEP' 'EOGReadingGr5_GLP_SWD'\n",
      " 'EOGReadingGr6_CACR_EDS' 'EOGReadingGr6_CACR_Female'\n",
      " 'EOGReadingGr6_CACR_LEP' 'EOGReadingGr6_CACR_Male'\n",
      " 'EOGReadingGr6_CACR_SWD' 'EOGReadingGr6_GLP_LEP' 'EOGReadingGr6_GLP_SWD'\n",
      " 'EOGReadingGr7_CACR_All' 'EOGReadingGr7_CACR_EDS'\n",
      " 'EOGReadingGr7_CACR_Female' 'EOGReadingGr7_CACR_LEP'\n",
      " 'EOGReadingGr7_CACR_Male' 'EOGReadingGr7_CACR_SWD'\n",
      " 'EOGReadingGr7_GLP_EDS' 'EOGReadingGr7_GLP_LEP' 'EOGReadingGr7_GLP_SWD'\n",
      " 'EOGReadingGr8_CACR_AIG' 'EOGReadingGr8_CACR_EDS'\n",
      " 'EOGReadingGr8_CACR_Female' 'EOGReadingGr8_CACR_LEP'\n",
      " 'EOGReadingGr8_CACR_Male' 'EOGReadingGr8_CACR_SWD'\n",
      " 'EOGReadingGr8_GLP_EDS' 'EOGReadingGr8_GLP_LEP' 'EOGReadingGr8_GLP_SWD'\n",
      " 'EOGScienceGr5&8_CACR_AIG' 'EOGScienceGr5&8_CACR_EDS'\n",
      " 'EOGScienceGr5&8_CACR_Female' 'EOGScienceGr5&8_CACR_LEP'\n",
      " 'EOGScienceGr5&8_CACR_Male' 'EOGScienceGr5&8_CACR_SWD'\n",
      " 'EOGScienceGr5&8_GLP_LEP' 'EOGScienceGr5&8_GLP_SWD'\n",
      " 'EOGScienceGr5_CACR_EDS' 'EOGScienceGr5_CACR_Female'\n",
      " 'EOGScienceGr5_CACR_LEP' 'EOGScienceGr5_CACR_Male'\n",
      " 'EOGScienceGr5_CACR_SWD' 'EOGScienceGr5_GLP_LEP' 'EOGScienceGr5_GLP_SWD'\n",
      " 'EOGScienceGr8_CACR_All' 'EOGScienceGr8_CACR_EDS'\n",
      " 'EOGScienceGr8_CACR_Female' 'EOGScienceGr8_CACR_Male'\n",
      " 'EOGScienceGr8_CACR_SWD' 'EOGScienceGr8_GLP_SWD' 'EOGSubjects_CACR_AIG'\n",
      " 'EOGSubjects_CACR_LEP' 'EOGSubjects_CACR_SWD' 'EOGSubjects_GLP_LEP'\n",
      " 'EOGSubjects_GLP_SWD' 'EVAAS Growth Score' 'EVAAS Growth Status_Met'\n",
      " 'EVAAS Growth Status_NotMet' 'English II Score' 'English II_Size'\n",
      " 'Exceeds Expected Growth_TCHR_Standard 6_Pct'\n",
      " 'Exceeds Expected Growth_TCHR_Student Growth_Pct'\n",
      " 'F_Female_ENROLL_sch_pct' 'Gr_6_Pct_Prof' 'Gr_9_Pct_Prof'\n",
      " 'Grad_project_status_Y' 'GraduationRate_4yr_AIG' 'GraduationRate_4yr_EDS'\n",
      " 'GraduationRate_4yr_Female' 'GraduationRate_4yr_LEP'\n",
      " 'GraduationRate_4yr_Male' 'GraduationRate_4yr_SWD'\n",
      " 'GraduationRate_5yr_AIG' 'GraduationRate_5yr_All'\n",
      " 'GraduationRate_5yr_EDS' 'GraduationRate_5yr_Female'\n",
      " 'GraduationRate_5yr_LEP' 'GraduationRate_5yr_Male'\n",
      " 'GraduationRate_5yr_SWD' 'HLTH_Concentrator_Ct' 'HOSP_Concentrator_Ct'\n",
      " 'INFO_Concentrator_Ct' 'LEP_Limited English Proficiency_ENROLL_sch_pct'\n",
      " 'MANU_Concentrator_Ct' 'MRKT_Concentrator_Ct'\n",
      " 'MU7_Multiracial_ENROLL_sch_pct' 'M_Male_ENROLL_sch_pct'\n",
      " 'Math Course Rigor Score' 'Math I Score' 'Math I_Size' 'Math SPG Grade'\n",
      " 'Math SPG Grade_B' 'Math SPG Grade_C' 'Math SPG Grade_D'\n",
      " 'Math SPG Grade_F' 'Math SPG Score' 'Math SPG Score_B' 'Math SPG Score_C'\n",
      " 'Math SPG Score_D' 'Math SPG Score_F' 'MathGr10_pTarget_PctMet'\n",
      " 'MathGr3-8_pTarget_PctMet' 'Meets Expected Growth_TCHR_Standard 6_Pct'\n",
      " 'Meets Expected Growth_TCHR_Student Growth_Pct' 'NC Math 1 Score'\n",
      " 'Not Demostrated_TCHR_Standard 1_Pct'\n",
      " 'Not Demostrated_TCHR_Standard 2_Pct'\n",
      " 'Not Demostrated_TCHR_Standard 3_Pct'\n",
      " 'Not Demostrated_TCHR_Standard 4_Pct'\n",
      " 'Not Demostrated_TCHR_Standard 5_Pct' 'Number_Industry_Recognized_Crede'\n",
      " 'PacificIslandFemalePct' 'PacificIslandMalePct' 'PacificIslandPct'\n",
      " 'Passing Math III' 'Passing NC Math 3' 'Proficient_TCHR_Standard 1_Pct'\n",
      " 'Proficient_TCHR_Standard 2_Pct' 'Proficient_TCHR_Standard 3_Pct'\n",
      " 'Proficient_TCHR_Standard 4_Pct' 'Proficient_TCHR_Standard 5_Pct'\n",
      " 'Reading  SPG Score' 'Reading SPG Grade' 'Reading SPG Grade_B'\n",
      " 'Reading SPG Grade_C' 'Reading SPG Grade_D' 'Reading SPG Grade_F'\n",
      " 'Reading SPG Score' 'Reading SPG Score_B' 'Reading SPG Score_C'\n",
      " 'Reading SPG Score_D' 'Reading SPG Score_F' 'ReadingGr10_pTarget_PctMet'\n",
      " 'ReadingGr3-8_pTarget_PctMet' 'SBE District_Northeast'\n",
      " 'SBE District_Northwest' 'SBE District_Piedmont-Triad'\n",
      " 'SBE District_Sandhills' 'SBE District_Southeast'\n",
      " 'SBE District_Southwest' 'SBE District_Western' 'SBE Region'\n",
      " 'SPG Grade_A+NG' 'SPG Grade_B' 'SPG Grade_C' 'SPG Grade_D' 'SPG Grade_F'\n",
      " 'SPG Grade_I' 'SPG Score' 'SRC_Grades_Devices_Sent_Home_10:11:12'\n",
      " 'SRC_Grades_Devices_Sent_Home_10:11:12:13'\n",
      " 'SRC_Grades_Devices_Sent_Home_3' 'SRC_Grades_Devices_Sent_Home_3:04:05'\n",
      " 'SRC_Grades_Devices_Sent_Home_4:05'\n",
      " 'SRC_Grades_Devices_Sent_Home_4:05:06' 'SRC_Grades_Devices_Sent_Home_5'\n",
      " 'SRC_Grades_Devices_Sent_Home_5:06' 'SRC_Grades_Devices_Sent_Home_6'\n",
      " 'SRC_Grades_Devices_Sent_Home_6:07:08'\n",
      " 'SRC_Grades_Devices_Sent_Home_6:7:8:9'\n",
      " 'SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12'\n",
      " 'SRC_Grades_Devices_Sent_Home_6:7:8:9:10:11:12:13'\n",
      " 'SRC_Grades_Devices_Sent_Home_7' 'SRC_Grades_Devices_Sent_Home_7:08'\n",
      " 'SRC_Grades_Devices_Sent_Home_8'\n",
      " 'SRC_Grades_Devices_Sent_Home_8:9:10:11:12:13'\n",
      " 'SRC_Grades_Devices_Sent_Home_9:10'\n",
      " 'SRC_Grades_Devices_Sent_Home_9:10:11'\n",
      " 'SRC_Grades_Devices_Sent_Home_9:10:11:12'\n",
      " 'SRC_Grades_Devices_Sent_Home_9:10:11:12:13'\n",
      " 'SRC_Grades_Devices_Sent_Home_9:10:12'\n",
      " 'SRC_Grades_Devices_Sent_Home_K:1:2:3:4:5'\n",
      " 'SRC_Grades_Devices_Sent_Home_K:1:2:3:4:5:6:7:8'\n",
      " 'SRC_Grades_Devices_Sent_Home_PK' 'SRC_devices_sent_home_Yes'\n",
      " 'STEM_Concentrator_Ct' 'SciGr11_pTarget_PctMet' 'SciGr5&8_pTarget_PctMet'\n",
      " 'Science Score' 'State Board Region_Northeast Region'\n",
      " 'State Board Region_Northwest Region'\n",
      " 'State Board Region_Piedmont Triad Region'\n",
      " 'State Board Region_SandHills Region'\n",
      " 'State Board Region_Southeast Region'\n",
      " 'State Board Region_Southwest Region' 'State Board Region_Western Region'\n",
      " 'State Gap Compared_Insufficient Data' 'State Gap Compared_Y'\n",
      " 'TRAN_Concentrator_Ct' 'The ACT Score' 'TotalTargets_pTarget_PctMet'\n",
      " 'WDIS_Students with Disabilities_ENROLL_sch_pct' 'Year'\n",
      " '_1_to_1_access_YES' '_1_to_1_access_Yes' '_1yr_tchr_trnovr_pct'\n",
      " 'advance_dgr_pct' 'ap_ib_courses' 'ap_participation_pct'\n",
      " 'ap_pct_3_or_above' 'avg_age_media_collection' 'avg_daily_attend_pct'\n",
      " 'books_per_student' 'calendar_only_txt_Year-Round Calendar'\n",
      " 'calendar_type_txt_Hospital School'\n",
      " 'calendar_type_txt_Magnet School, Traditional Calendar'\n",
      " 'calendar_type_txt_Magnet School, Year-Round Calendar'\n",
      " 'calendar_type_txt_Regular School, Traditional Calendar'\n",
      " 'calendar_type_txt_Regular School, Traditional Calendar plus Year-Round Calendar'\n",
      " 'calendar_type_txt_Regular School, Year-Round Calendar'\n",
      " 'calendar_type_txt_Special Education, Traditional Calendar'\n",
      " 'calendar_type_txt_Vocational Education, Traditional Calendar'\n",
      " 'category_cd_E' 'category_cd_H' 'category_cd_I' 'category_cd_M'\n",
      " 'category_cd_T' 'class_teach_num' 'closed_ind' 'cte_courses'\n",
      " 'digital_media_pct' 'emer_prov_teach_pct' 'esea_attendance_Met'\n",
      " 'esea_status_P' 'esea_status_R' 'esea_status_RF' 'esea_status_RP'\n",
      " 'expelled_per_c_num' 'flicensed_teach_pct' 'grade_range_cd_11-12'\n",
      " 'grade_range_cd_11-13' 'grade_range_cd_3-12' 'grade_range_cd_4-8'\n",
      " 'grade_range_cd_5-6' 'grade_range_cd_5-8' 'grade_range_cd_6-11'\n",
      " 'grade_range_cd_6-12' 'grade_range_cd_6-13' 'grade_range_cd_6-6'\n",
      " 'grade_range_cd_6-7' 'grade_range_cd_6-8' 'grade_range_cd_6-9'\n",
      " 'grade_range_cd_7-12' 'grade_range_cd_7-13' 'grade_range_cd_7-8'\n",
      " 'grade_range_cd_7-9' 'grade_range_cd_8-12' 'grade_range_cd_8-13'\n",
      " 'grade_range_cd_8-8' 'grade_range_cd_9-10' 'grade_range_cd_9-11'\n",
      " 'grade_range_cd_9-12' 'grade_range_cd_9-13' 'grade_range_cd_9-9'\n",
      " 'grade_range_cd_K-12' 'grade_range_cd_K-8' 'grade_range_cd_PK-12'\n",
      " 'grade_range_cd_PK-13' 'grade_range_cd_PK-7' 'grade_range_cd_PK-8'\n",
      " 'grade_range_cd_PK-9' 'grades_1_to_1_access_10:11:12'\n",
      " 'grades_1_to_1_access_10:11:12:13' 'grades_1_to_1_access_11'\n",
      " 'grades_1_to_1_access_11:12' 'grades_1_to_1_access_11:12:13'\n",
      " 'grades_1_to_1_access_1:2:3:4:5:6:7:8'\n",
      " 'grades_1_to_1_access_2:3:4:5:6:7:8' 'grades_1_to_1_access_3'\n",
      " 'grades_1_to_1_access_3:04:05' 'grades_1_to_1_access_3:4:5:6:7:8'\n",
      " 'grades_1_to_1_access_4' 'grades_1_to_1_access_4:05'\n",
      " 'grades_1_to_1_access_4:05:06' 'grades_1_to_1_access_4:5:6:7:8'\n",
      " 'grades_1_to_1_access_5' 'grades_1_to_1_access_5:06'\n",
      " 'grades_1_to_1_access_5:6:7:8' 'grades_1_to_1_access_6'\n",
      " 'grades_1_to_1_access_6:07' 'grades_1_to_1_access_6:07:08'\n",
      " 'grades_1_to_1_access_6:08' 'grades_1_to_1_access_6:7:8:9:10'\n",
      " 'grades_1_to_1_access_6:7:8:9:10:11:12'\n",
      " 'grades_1_to_1_access_6:7:8:9:10:11:12:13'\n",
      " 'grades_1_to_1_access_6:7:8:9:10:11:12:Early College'\n",
      " 'grades_1_to_1_access_7' 'grades_1_to_1_access_7:08'\n",
      " 'grades_1_to_1_access_7:08:09' 'grades_1_to_1_access_8'\n",
      " 'grades_1_to_1_access_9' 'grades_1_to_1_access_9:10'\n",
      " 'grades_1_to_1_access_9:10:11' 'grades_1_to_1_access_9:10:11:12'\n",
      " 'grades_1_to_1_access_9:10:11:12:.Early College'\n",
      " 'grades_1_to_1_access_9:10:11:12:13'\n",
      " 'grades_1_to_1_access_9:10:11:12:Early'\n",
      " 'grades_1_to_1_access_9:10:11:12:Early College'\n",
      " 'grades_1_to_1_access_9:10:12' 'grades_1_to_1_access_9:11:12:13'\n",
      " 'grades_1_to_1_access_9:12' 'grades_1_to_1_access_Early College'\n",
      " 'grades_1_to_1_access_K:1:2:3' 'grades_1_to_1_access_K:1:2:3:4:5'\n",
      " 'grades_1_to_1_access_K:1:2:3:4:5:6:7:8'\n",
      " 'grades_1_to_1_access_K:1:2:3:4:5:6:7:8:9:10:11:12'\n",
      " 'grades_1_to_1_access_K:7:8' 'grades_1_to_1_access_PK'\n",
      " 'grades_1_to_1_access_PK:K:1:2:3:4:5:6:7:8' 'grades_BYOD_10:11:12'\n",
      " 'grades_BYOD_11:12' 'grades_BYOD_11:12:13' 'grades_BYOD_12'\n",
      " 'grades_BYOD_1:2:3:4:5:6:7:8:9:10:11:12:Early College'\n",
      " 'grades_BYOD_3:4:5:6:7:8' 'grades_BYOD_3:4:5:6:7:8:9:10:11:12'\n",
      " 'grades_BYOD_4:05:06' 'grades_BYOD_4:06' 'grades_BYOD_4:5:6:7:8'\n",
      " 'grades_BYOD_5' 'grades_BYOD_5:06' 'grades_BYOD_5:6:7:8' 'grades_BYOD_6'\n",
      " 'grades_BYOD_6:07' 'grades_BYOD_6:07:08' 'grades_BYOD_6:07:09'\n",
      " 'grades_BYOD_6:08' 'grades_BYOD_6:7:8:9:10:11:12'\n",
      " 'grades_BYOD_6:7:8:9:10:11:12:13' 'grades_BYOD_7' 'grades_BYOD_7:08'\n",
      " 'grades_BYOD_7:8:9:10:11:12' 'grades_BYOD_8' 'grades_BYOD_8:9:10:11:12'\n",
      " 'grades_BYOD_9' 'grades_BYOD_9:10' 'grades_BYOD_9:10:11'\n",
      " 'grades_BYOD_9:10:11:12' 'grades_BYOD_9:10:11:12:13'\n",
      " 'grades_BYOD_9:10:11:12:Early College' 'grades_BYOD_9:11:12'\n",
      " 'grades_BYOD_9:12' 'grades_BYOD_Early College'\n",
      " 'grades_BYOD_K:1:2:3:4:5:6:7:8' 'grades_BYOD_PK:6:7:8'\n",
      " 'grades_BYOD_PK:9:10:11:12' 'grades_BYOD_PK:K:1:2:3:4:5:6:7'\n",
      " 'grades_BYOD_PK:K:1:2:3:4:5:6:7:8'\n",
      " 'grades_BYOD_PK:K:1:2:3:4:5:6:7:8:9:10:11:12:13'\n",
      " 'grades_BYOD_PK:K:1:2:3:4:5:7:8' 'grades_BYOD_PreK:1:2:3:4:5:6:7:8'\n",
      " 'grades_BYOD_PreK:1:2:3:4:5:6:7:8:9:10:11:12:Early College'\n",
      " 'grades_BYOD_PreK:K:1:2:3:4:5:6:7:8' 'highqual_class_pct'\n",
      " 'lateral_teach_pct' 'long_susp_per_c_num' 'nbpts_num' 'pct_GCE_ALL'\n",
      " 'pct_GCE_SWD' 'pct_PASSED_LAA' 'pct_PROMOTED' 'pct_RETAINED' 'pct_eds'\n",
      " 'sat_avg_score_num' 'sat_participation_pct'\n",
      " 'school_type_txt_Magnet School' 'school_type_txt_Regular School'\n",
      " 'short_susp_per_c_num' 'stud_internet_comp_num' 'student_num'\n",
      " 'tchyrs_0thru3_pct' 'tchyrs_11plus_pct' 'tchyrs_4thru10_pct'\n",
      " 'total_specialized_courses' 'univ_college_courses' 'wap_num'\n",
      " 'wap_per_classroom']\n"
     ]
    }
   ],
   "source": [
    "print(X_crime_reduced.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6750940987337503\n"
     ]
    }
   ],
   "source": [
    " param_grid = [\n",
    "    {\n",
    "         'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "         'clf__n_estimators': C_ESTIMATORS, \n",
    "         'clf__max_depth': C_DEPTH,\n",
    "     }\n",
    "]\n",
    "\n",
    "\n",
    "# # This will test the parameter dict against our \n",
    "# # pipeline\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=1 )\n",
    "\n",
    "\n",
    "# # Here we are training the model, this is \n",
    "# # what takes the most amount of time to run\n",
    "crime_reduced_GradientBoost_model = grid_search.fit(X_crime_reduced_train, y_crime_reduced_train)\n",
    "\n",
    "\n",
    "y_crime_reduced_score = grid_search.predict(X_crime_reduced_test)\n",
    "\n",
    "print(roc_auc_score(y_crime_reduced_test, y_crime_reduced_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', SelectKBest(k='all', score_func=<function chi2 at 0x7ff484499620>)), ('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=5, ma...rs=50, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(**crime_reduced_GradientBoost_model.best_params_)\n",
    "pipe.fit(X_crime_reduced_train, y_crime_reduced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 features that influence SPG Grade are the following\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Influence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>short_susp_per_c_num</th>\n",
       "      <td>0.095112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_daily_attend_pct</th>\n",
       "      <td>0.046270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_All</th>\n",
       "      <td>0.027405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPG Score</th>\n",
       "      <td>0.019949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_num</th>\n",
       "      <td>0.019401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stud_internet_comp_num</th>\n",
       "      <td>0.016367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVAAS Growth Score</th>\n",
       "      <td>0.015583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advance_dgr_pct</th>\n",
       "      <td>0.015271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>books_per_student</th>\n",
       "      <td>0.014892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_susp_per_c_num</th>\n",
       "      <td>0.013610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital_media_pct</th>\n",
       "      <td>0.012521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG/EOCSubjects_CACR_EDS</th>\n",
       "      <td>0.011887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOGScienceGr8_GLP_SWD</th>\n",
       "      <td>0.011385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOGMathGr3-8_CACR_EDS</th>\n",
       "      <td>0.011039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOGReadingGr5_GLP_SWD</th>\n",
       "      <td>0.009706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_1yr_tchr_trnovr_pct</th>\n",
       "      <td>0.009103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_Size</th>\n",
       "      <td>0.008913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exceeds Expected Growth_TCHR_Standard 6_Pct</th>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tchyrs_0thru3_pct</th>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOGGr8_CACR_EDS</th>\n",
       "      <td>0.008035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Influence\n",
       "short_susp_per_c_num                          0.095112\n",
       "avg_daily_attend_pct                          0.046270\n",
       "EOG/EOCSubjects_CACR_All                      0.027405\n",
       "SPG Score                                     0.019949\n",
       "student_num                                   0.019401\n",
       "stud_internet_comp_num                        0.016367\n",
       "EVAAS Growth Score                            0.015583\n",
       "advance_dgr_pct                               0.015271\n",
       "books_per_student                             0.014892\n",
       "long_susp_per_c_num                           0.013610\n",
       "digital_media_pct                             0.012521\n",
       "EOG/EOCSubjects_CACR_EDS                      0.011887\n",
       "EOGScienceGr8_GLP_SWD                         0.011385\n",
       "EOGMathGr3-8_CACR_EDS                         0.011039\n",
       "EOGReadingGr5_GLP_SWD                         0.009706\n",
       "_1yr_tchr_trnovr_pct                          0.009103\n",
       "03_Size                                       0.008913\n",
       "Exceeds Expected Growth_TCHR_Standard 6_Pct   0.008696\n",
       "tchyrs_0thru3_pct                             0.008463\n",
       "EOGGr8_CACR_EDS                               0.008035"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = pipe.steps[2][1].feature_importances_\n",
    "\n",
    "mask = pipe.steps[0][1].get_support()\n",
    "new_features=[]\n",
    "feature_names=list(X_crime_reduced_train.columns.values)\n",
    "for bool, feature in zip(mask, feature_names):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "\n",
    "#Creates a new dataframe with the coefficients and the \n",
    "predicted_data = pd.DataFrame(data=coef,index=new_features,columns=['Influence'])\n",
    "print(\"The top 20 features that influence SPG Grade are the following\")\n",
    "\n",
    "\n",
    "\n",
    "display(predicted_data.sort_values(by='Influence', ascending=False)[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.d Modeling and Evaluation\n",
    "10 points - Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run this to load the model from the save file\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "# grid_search = joblib.load('savedBestModel.pkl')\n",
    "\n",
    "\n",
    "# # Loads all parameters run into a dict \n",
    "\n",
    "# params = np.array(grid_search.cv_results_['params'])\n",
    "\n",
    "\n",
    "# # Loads all mean test scores into an array\n",
    "\n",
    "# mean_scores = np.array(grid_search.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assigns all models to an array\n",
    "\n",
    "# classifier_labels=['SVC','LogisticRegression','SGDClassifier']\n",
    "\n",
    "\n",
    "# # Creates an empty dataframe that is to be\n",
    "# # filled with the mean test accuracy by C global\n",
    "# # variable and the different classifiers\n",
    "\n",
    "# classifier_temp = pd.DataFrame(columns=classifier_labels,index=C_OPTIONS,\n",
    "#                                data=np.linspace(.1,.25,num=len(C_OPTIONS)*len(classifier_labels)).reshape(len(C_OPTIONS),len(classifier_labels)))\n",
    "# classifier_temp.fillna(0,inplace=True)\n",
    "\n",
    "# for i, (param, score) in enumerate(zip(params, mean_scores)):\n",
    "#     C = param['clf__C'] if 'clf__C' in param else param['clf__alpha']\n",
    "#     class_state = str(param['clf']).split('(')[0]\n",
    "#     if classifier_temp.at[C,class_state] < score:\n",
    "#         classifier_temp.at[C,class_state] = score\n",
    "\n",
    "\n",
    "# # Printing a grid of the best accuracies\n",
    "        \n",
    "# display(classifier_temp.transpose())   \n",
    "\n",
    "\n",
    "# # Print a line plot which shows the best \n",
    "# # accuracies\n",
    " \n",
    "# classifier_temp.plot(logx=True,ylim=(0,1),figsize=(14,10),title='Accuracy by Classifier'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assigns all reduction models to an array\n",
    "\n",
    "# reduce_labels=['NMF','PCA','SelectKBest']\n",
    "\n",
    "\n",
    "# # Translates the N Features array\n",
    "# # to an array full of string\n",
    "\n",
    "# temp_N_FEATURES_OPTIONS = [str(r) for r in N_FEATURES_OPTIONS]\n",
    "# temp_N_FEATURES_OPTIONS=temp_N_FEATURES_OPTIONS+['None']\n",
    "\n",
    "\n",
    "# # Creates an empty dataframe that is to be\n",
    "# # filled with the mean test accuracy by N Features\n",
    "# # variable and the different feature reduction models\n",
    "\n",
    "# reduce_temp = pd.DataFrame(columns=reduce_labels,index=temp_N_FEATURES_OPTIONS,\n",
    "#                                data=np.linspace(.1,.25,num=len(temp_N_FEATURES_OPTIONS)*len(reduce_labels)).reshape(+len(temp_N_FEATURES_OPTIONS),len(reduce_labels)))\n",
    "\n",
    "\n",
    "# for i, (param, score) in enumerate(zip(params, mean_scores)):\n",
    "#     trigger=0\n",
    "#     reduce_state = str(param['reduce_dim']).split('(')[0]\n",
    "#     if 'reduce_dim__k' in param:\n",
    "#         N_FEAT = str(param['reduce_dim__k'])\n",
    "#         trigger=1\n",
    "#     elif 'reduce_dim__n_components' in param:\n",
    "#         N_FEAT = str(param['reduce_dim__n_components'])\n",
    "#         trigger=1\n",
    "#     else:\n",
    "#         if reduce_temp.at['None','NMF'] < score:\n",
    "#             reduce_temp.at['None','NMF'] = score\n",
    "#             reduce_temp.at['None','SelectKBest'] = score\n",
    "#     if trigger == 1:\n",
    "#         if reduce_temp.at[N_FEAT,reduce_state] < score:\n",
    "#             reduce_temp.at[N_FEAT,reduce_state] = score\n",
    "\n",
    "            \n",
    "# # Printing a grid of the best accuracies\n",
    "\n",
    "# display(reduce_temp.transpose())\n",
    "\n",
    "\n",
    "# # Print a bar plot which shows the best \n",
    "# # accuracies\n",
    "\n",
    "# reduce_temp.plot(kind='bar',ylim=(0,1),figsize=(14,10),title='Accuracy by Feature Selection',rot=0);           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The Index of the best model is',grid_search.best_index_)\n",
    "# print('The parameters of the best model is')\n",
    "# display(grid_search.best_params_)\n",
    "# print('The accuracy of the best model is',round(grid_search.best_score_*100,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.e Modeling and Evaluation\n",
    "10 points - Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference signiﬁcant with 95% conﬁdence? Use proper statistical comparison methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.f Modeling and Evaluation\n",
    "10 points - Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classiﬁcation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "5 points - How useful is yolur model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "10 points - You have free reign to provide additional modeling. \n",
    "One idea: grid search parameters in a parallelized fashion and visualize the \n",
    "performances across attributes. Which parameters are most signiﬁcant for making a \n",
    "good model for each classiﬁcation algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
