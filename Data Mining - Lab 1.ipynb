{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "\n",
    "<b>Class:</b> MSDS 7331 Data Mining\n",
    "<br> <b>Dataset:</b> Belk Endowment Educational Attainment Data \n",
    "\n",
    "<h1 style=\"font-size:150%;\"> Teammates </h1>\n",
    "Maryam Shahini\n",
    "<br> Murtada Shubbar\n",
    "<br> Michael Toolin\n",
    "<br> Steven Millett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_school_2014_data = pd.read_csv('./Data/2014/PublicSchools2014.csv', low_memory=False)\n",
    "public_school_2015_data = pd.read_csv('./Data/School Datasets/PublicSchools2015.csv', low_memory=False)\n",
    "public_school_2016_data = pd.read_csv('./Data/School Datasets/PublicSchools2016.csv', low_memory=False)\n",
    "public_school_2017_data = pd.read_csv('./Data/School Datasets/PublicSchools2017.csv', low_memory=False)\n",
    "#\n",
    "# The below uses the ML data set rather than the full data set which will be used through out the project\n",
    "# To shorten the Data frame names, the _ml suffix is removed\n",
    "#\n",
    "all_pub_school_data_2017 = pd.read_csv('./Data/Machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)\n",
    "all_pub_school_data_2016 = pd.read_csv('./Data/Machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)\n",
    "all_pub_school_data_2015 = pd.read_csv('./Data/Machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)\n",
    "all_pub_school_data_2014 = pd.read_csv('./Data/Machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2617, 1279)\n",
      "(2585, 1256)\n",
      "(2599, 1256)\n",
      "(2617, 1279)\n",
      "(2443, 334)\n",
      "(1268, 311)\n",
      "(526, 402)\n",
      "(470, 403)\n"
     ]
    }
   ],
   "source": [
    "print(public_school_2017_data.shape)\n",
    "print(public_school_2015_data.shape)\n",
    "print(public_school_2016_data.shape)\n",
    "print(public_school_2017_data.shape)\n",
    "#\n",
    "# Use ML data sets\n",
    "#\n",
    "print(all_pub_school_2017_data_ml.shape)\n",
    "print(elem_school_2017_data_ml.shape)\n",
    "print(middle_school_2017_data_ml.shape)\n",
    "print(high_school_2017_data_ml.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_public_school_data = pd.concat([public_school_2014_data, public_school_2015_data,\n",
    "                                       public_school_2016_data, public_school_2017_data], axis =0, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10362, 1318)\n"
     ]
    }
   ],
   "source": [
    "print(master_public_school_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_public_school = master_public_school_data.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding \n",
    "\n",
    "The North Carolina Educational data set contains report cards on a variety of schools in the North Carolina school system. These include public schools, charter schools and alternative schools.  This data describes the school system at multiple levels and grades the schools on a number of different metrics.  The number of different metrics available provide an opportunity to measure schools on all these different performance areas.  One area to look closely into is school and student performance.  These specific metrics can provide some insight into indivdual schools or schools in parts of the state that are underperforming where additional resources might help.  North Carolina ranks 40th in the nation in eduction and ranks 45th in funding.[1] The lack of financial resources places a premium on deciding where to use the available money. For example, how are districts with primarliy minority students fairing compared to others? Where schools are underperforming, how experienced are teachers?  Using this data to identify underperforming areas, can we predict if higher funding correlates to better performance in school or on SAT scores. Also, are college admissions in any way connected to better funded schools.  A seperate area to examine would be the safety of neighborhoods in comparison to school performance.  This information could be used in other areas of local government as well.\n",
    "\n",
    "###citation: Drew J., The Belk Endowment Educational Attainment Data Repository for North Carolina Public Schools, (2018), GitHub repository, https://github.com/jakemdrew/EducationDataNC\n",
    "\n",
    "[1] (source: https://www.edweek.org/ew/collections/quality-counts-2018-state-grades/highlight-reports/2018/01/17/north-carolina.html/)\n",
    "\n",
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). Describe how you would define and measure the outcomes from the dataset. That is, why is this data important and how do you know if you have mined useful knowledge from the dataset? How would you measure the effectiveness of a good prediction algorithm? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Meaning Type \n",
    "\n",
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2443 entries, 0 to 2442\n",
      "Columns: 334 entries, student_num to unit_code\n",
      "dtypes: float64(290), int64(44)\n",
      "memory usage: 6.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_pub_school_2017_data_ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_num</th>\n",
       "      <th>lea_avg_student_num</th>\n",
       "      <th>st_avg_student_num</th>\n",
       "      <th>00_Size</th>\n",
       "      <th>02_Size</th>\n",
       "      <th>03_Size</th>\n",
       "      <th>04_Size</th>\n",
       "      <th>05_Size</th>\n",
       "      <th>Math I_Size</th>\n",
       "      <th>lea_total_expense_num</th>\n",
       "      <th>...</th>\n",
       "      <th>Math SPG Grade_C</th>\n",
       "      <th>Math SPG Grade_D</th>\n",
       "      <th>Math SPG Grade_F</th>\n",
       "      <th>EVAAS Growth Status_Met</th>\n",
       "      <th>EVAAS Growth Status_NotMet</th>\n",
       "      <th>State Gap Compared_Y</th>\n",
       "      <th>Byod_Yes</th>\n",
       "      <th>_1_to_1_access_Yes</th>\n",
       "      <th>SRC_devices_sent_home_Yes</th>\n",
       "      <th>unit_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8588.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>575.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8588.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>611.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8588.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>742.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8588.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8588.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_num  lea_avg_student_num  st_avg_student_num  00_Size  02_Size  \\\n",
       "0        152.0                996.0               853.0      0.0      0.0   \n",
       "1        575.0                528.0               490.0     21.0     19.0   \n",
       "2        611.0                528.0               490.0     19.0     20.0   \n",
       "3        742.0                706.0               629.0      0.0      0.0   \n",
       "4        701.0                528.0               490.0     20.0     21.0   \n",
       "\n",
       "   03_Size  04_Size  05_Size  Math I_Size  lea_total_expense_num    ...      \\\n",
       "0      0.0      0.0      0.0         21.0                8588.32    ...       \n",
       "1     22.0     24.0     28.0          0.0                8588.32    ...       \n",
       "2     19.0     27.0     26.0          0.0                8588.32    ...       \n",
       "3      0.0      0.0      0.0         26.0                8588.32    ...       \n",
       "4     22.0     24.0     23.0          0.0                8588.32    ...       \n",
       "\n",
       "   Math SPG Grade_C  Math SPG Grade_D  Math SPG Grade_F  \\\n",
       "0                 0                 0                 0   \n",
       "1                 0                 0                 0   \n",
       "2                 1                 0                 0   \n",
       "3                 0                 0                 1   \n",
       "4                 1                 0                 0   \n",
       "\n",
       "   EVAAS Growth Status_Met  EVAAS Growth Status_NotMet  State Gap Compared_Y  \\\n",
       "0                        1                           0                     0   \n",
       "1                        0                           0                     0   \n",
       "2                        0                           0                     0   \n",
       "3                        1                           0                     0   \n",
       "4                        0                           1                     0   \n",
       "\n",
       "   Byod_Yes  _1_to_1_access_Yes  SRC_devices_sent_home_Yes  unit_code  \n",
       "0         0                   1                          1      10303  \n",
       "1         0                   0                          0      10304  \n",
       "2         0                   0                          0      10308  \n",
       "3         0                   0                          0      10310  \n",
       "4         0                   0                          0      10312  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pub_school_2017_data_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatter_matrix(school_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2443, 334)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pub_school_2017_data_ml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality\n",
    "\n",
    "Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Statistics\n",
    "\n",
    "Visualize appropriate statistics (e.g., range, mode, mean, median, variance, counts) for a subset of attributes. Describe anything meaningful you found from this or if you found something potentially interesting. Note: You can also use data from other sources for comparison. Explain why the statistics run are meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       All Students        Female          Male  American Indian  \\\n",
      "count  85766.000000  85766.000000  85766.000000     85766.000000   \n",
      "mean      53.283481     53.230942     50.816355         2.641560   \n",
      "std       21.763396     23.302157     23.236344        11.432818   \n",
      "min        0.000000      0.000000      0.000000         0.000000   \n",
      "25%       38.500000     38.400000     35.500000         0.000000   \n",
      "50%       53.300000     54.200000     51.000000         0.000000   \n",
      "75%       68.000000     69.200000     66.700000         0.000000   \n",
      "max      100.000000    100.000000    100.000000       100.000000   \n",
      "\n",
      "              Asian         Black      Hispanic  Two or More Races  \\\n",
      "count  85766.000000  85766.000000  85766.000000       85766.000000   \n",
      "mean      14.049401     27.208183     31.674390          19.312606   \n",
      "std       30.039769     24.178638     26.918454          28.433244   \n",
      "min        0.000000      0.000000      0.000000           0.000000   \n",
      "25%        0.000000      0.000000      0.000000           0.000000   \n",
      "50%        0.000000     26.100000     33.300000           0.000000   \n",
      "75%        0.000000     42.200000     50.400000          42.300000   \n",
      "max      100.000000    100.000000    100.000000         100.000000   \n",
      "\n",
      "              White           EDS      ...        American Indian_Ct  \\\n",
      "count  85766.000000  85766.000000      ...              85766.000000   \n",
      "mean      56.453993     40.101511      ...                 12.292097   \n",
      "std       27.656753     21.970242      ...                196.190122   \n",
      "min        0.000000      0.000000      ...                  5.000000   \n",
      "25%       44.100000     26.200000      ...                  5.000000   \n",
      "50%       61.500000     39.100000      ...                  5.000000   \n",
      "75%       76.200000     52.900000      ...                  5.000000   \n",
      "max      100.000000    100.000000      ...              24464.000000   \n",
      "\n",
      "           Asian_Ct       Black_Ct    Hispanic_Ct  Two or More Races_Ct  \\\n",
      "count  85766.000000   85766.000000   85766.000000          85766.000000   \n",
      "mean      24.364538     174.537999     117.599037             29.467831   \n",
      "std      483.668489    3705.367580    2502.602658            606.965166   \n",
      "min        5.000000       5.000000       5.000000              5.000000   \n",
      "25%        5.000000       5.000000       5.000000              5.000000   \n",
      "50%        5.000000      30.000000      21.000000              5.000000   \n",
      "75%        5.000000      84.000000      57.000000             15.000000   \n",
      "max    64469.000000  509546.000000  342683.000000          83948.000000   \n",
      "\n",
      "            White_Ct         EDS_Ct        LEP_Ct         SWD_Ct  \\\n",
      "count   85766.000000   85766.000000  85766.000000   85766.000000   \n",
      "mean      341.109239     340.091948     33.879404      86.061773   \n",
      "std      7152.878031    7199.694882    715.061354    1850.959176   \n",
      "min         5.000000       5.000000      5.000000       5.000000   \n",
      "25%        26.000000      35.000000      5.000000       5.000000   \n",
      "50%        69.000000      78.000000      5.000000      19.000000   \n",
      "75%       177.000000     177.000000     15.000000      45.000000   \n",
      "max    998834.000000  995415.000000  95195.000000  255617.000000   \n",
      "\n",
      "              AIG_Ct  \n",
      "count   85766.000000  \n",
      "mean      106.320034  \n",
      "std      2174.148030  \n",
      "min         5.000000  \n",
      "25%         5.000000  \n",
      "50%        17.000000  \n",
      "75%        49.000000  \n",
      "max    305064.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(school_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Attributes\n",
    "\n",
    "Visualize the most interesting attributes (at least 5 attributes, your opinion on what is interesting). Important: Interpret the implications for each visualization. Explain for each attribute why the chosen visualization is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Joint Attributes\n",
    "\n",
    "Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Attributes and Class\n",
    "\n",
    "Identify and explain interesting relationships between features and the class you are trying to predict (i.e., relationships with variables and the target classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features\n",
    "\n",
    "Are there other features that could be added to the data or created from existing features? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses. One idea: implement dimensionality reduction, then visualize and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
