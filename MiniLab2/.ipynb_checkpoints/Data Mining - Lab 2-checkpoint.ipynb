{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minilab 2\n",
    "\n",
    "<b>Class:</b> MSDS 7331 Data Mining\n",
    "<br> <b>Dataset:</b> Belk Endowment Educational Attainment Data \n",
    "\n",
    "<h1 style=\"font-size:150%;\"> Teammates </h1>\n",
    "Maryam Shahini\n",
    "<br> Murtada Shubbar\n",
    "<br> Michael Toolin\n",
    "<br> Steven Millett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import math\n",
    "import re\n",
    "import statistics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The 2017 Public Schools Machine Learning Date Set is being used throughout this analysis.  The _ML suffix is removed to less name space size\n",
    "#\n",
    "# Load Full Public School Data Frames for each year\n",
    "\n",
    "school_data = pd.read_csv('../Data/2017/machine Learning Datasets/PublicSchools2017_ML.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models\n",
    "Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split data into X and y dataframes\n",
    "\n",
    "SPG_Grade_col = school_data.filter(regex=('^SPG\\WGrade')).columns\n",
    "y = school_data[SPG_Grade_col].apply(lambda row:'A' if row.any()!=1 else \n",
    "                                 row[0]*'A+NG'+row[1]*'B'+row[2]*'C'+row[3]*'D'+row[4]*'F'+row[5]*'I',axis=1)\n",
    "\n",
    "#Removed SPG Grade and unit code(which is primary key for school data table)\n",
    "X = school_data[school_data.columns.drop(list(school_data.filter(regex='^SPG\\WGrade|unit_code')))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split X and y into test and train sets.\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #applied a scaling procedure to scale the size of variables in the x dataframe\n",
    "\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train_scale = sc.fit_transform(X_train)\n",
    "# X_test_scale = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initializing the Logistic Regression function to a classifier variable\n",
    "# Log_Reg_classifier = LogisticRegression()\n",
    "\n",
    "# #Log_Reg = RFE(Log_Reg_classifier\n",
    "\n",
    "\n",
    "# #Fitting the Logistic Regression Classifier to the original dataset and then predicting.\n",
    "# Log_Reg_classifier.fit(X_train, y_train)\n",
    "# y_pred_Log_Reg = Log_Reg_classifier.predict(X_test)\n",
    "\n",
    "# #Fitting the Logistic Regression Classifier to the scaled dataset and then predicting.\n",
    "# Log_Reg.fit(X_train_scale, y_train)\n",
    "# y_pred_Log_Reg_scale = Log_Reg_classifier.predict(X_test_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the confusion matrix and accuracy score for SVM without scaling. Based on the accuracy score it is evident that Logistic Regression handles non-standardized variables relatively well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Created a confusion matrix for the \n",
    "# cm_Log_Reg = confusion_matrix(y_test, y_pred_Log_Reg)\n",
    "\n",
    "# print(cm_Log_Reg)\n",
    "# print('Test dataset accuracy '+round(accuracy_score(y_test, y_pred_Log_Reg),6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the confusion matrix and accuracy score for logistic regression with scaling. Based on the accuracy score it is obvious that the logistic model is negatively affected by the different scales of the dataset, but the scaled model does not dramatically improve the fit of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_Log_Reg_scale = confusion_matrix(y_test, y_pred_Log_Reg_scale)\n",
    "\n",
    "# print(cm_Log_Reg_scale)\n",
    "# print('Test dataset with scaling accuracy '+round(accuracy_score(y_test, y_pred_Log_Reg_scale),6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initializing the SVM function to a classifier variable\n",
    "# classifier = svm.SVC()\n",
    "\n",
    "# #Fitting the SVM Classifier to the original dataset and then predicting.\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred_svm = classifier.predict(X_test)\n",
    "\n",
    "# #Fitting the SVM Classifier to the scaled dataset and then predicting.\n",
    "# classifier.fit(X_train_scale, y_train)\n",
    "# y_pred_svm_scale = classifier.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the confusion matrix and accuracy score for SVM without scaling. Based on the accuracy score it is obvious that SVM is heavily influenced by non-standardized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Assigning a confusion matrix with the original dataset.\n",
    "# cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# print(cm_svm)\n",
    "# print(accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have the confusion matrix and accuracy score for SVM with scaling. Based on the accuracy score it is obvious that the SVM model is negatively affected by the different scales of the dataset. With the use of the standard scaler function we find that SVM is a superior model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Assigning a confusion matrix with the scaled dataset.\n",
    "# cm_svm_scale = confusion_matrix(y_test, y_pred_svm_scale)\n",
    "\n",
    "# print(cm_svm_scale)\n",
    "# print(accuracy_score(y_test, y_pred_svm_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##STM - 6/6/18\n",
    "\n",
    "# numFolds = 10\n",
    "# kf = KFold(len(y_train), numFolds, shuffle=True)\n",
    "\n",
    "# # These are \"Class objects\". For each Class, find the AUC through\n",
    "# # 10 fold cross validation.\n",
    "# Models = [LogisticRegression, SGDClassifier, svm.SVC, LinearSVC]\n",
    "# params = [{C=.01}, {\"loss\": \"log\", \"penalty\": \"l2\", 'max_iter':1000},{},{}]\n",
    "# for param, Model in zip(params, Models):\n",
    "#     total = 0\n",
    "#     for train_indices, test_indices in kf:\n",
    "\n",
    "#         #print(X_train.iloc[train_indices])\n",
    "#         #print(y_train.iloc[train_indices])\n",
    "#         train_X = X_train.iloc[train_indices]; \n",
    "#         train_Y = y_train.iloc[train_indices]\n",
    "#         test_X = X_train.iloc[test_indices]; \n",
    "#         test_Y = y_train.iloc[test_indices]\n",
    "\n",
    "#         reg = Model(**param)\n",
    "#         reg.fit(train_X, train_Y)\n",
    "#         predictions = reg.predict(test_X)\n",
    "#         total += accuracy_score(test_Y, predictions)\n",
    "#     accuracy = total / numFolds\n",
    "#     external_predict = accuracy_score(y_test, reg.predict(X_test))\n",
    "\n",
    "#     print (\"External CV accuracy score of {0}: {1}\".format(\n",
    "#             Model.__name__,round(external_predict,6)))\n",
    "#     print (\"Internal CV accuracy score of {0}: {1}\".format(Model.__name__, round(accuracy, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##STM - 6/6/18\n",
    "\n",
    "# numFolds = 10\n",
    "# kf = KFold(len(y_train), numFolds, shuffle=True)\n",
    "\n",
    "# # These are \"Class objects\". For each Class, find the AUC through\n",
    "# # 10 fold cross validation.\n",
    "# Models = [LogisticRegression, SGDClassifier, svm.SVC, LinearSVC]\n",
    "# params = [{}, {\"loss\": \"log\", \"penalty\": \"l2\", 'max_iter':1000},{},{}]\n",
    "# for param, Model in zip(params, Models):\n",
    "#     total = 0\n",
    "#     for train_indices, test_indices in kf:\n",
    "#         #print(X_train.iloc[train_indices])\n",
    "#         #print(y_train.iloc[train_indices])\n",
    "#         train_X = X_train_scale[train_indices, :]; \n",
    "#         train_Y = y_train.iloc[train_indices]\n",
    "#         test_X = X_train_scale[test_indices, :]; \n",
    "#         test_Y = y_train.iloc[test_indices]\n",
    "\n",
    "#         reg = Model(**param)\n",
    "#         reg.fit(train_X, train_Y)\n",
    "#         predictions = reg.predict(test_X)\n",
    "#         total += accuracy_score(test_Y, predictions)\n",
    "#     accuracy = total / numFolds\n",
    "#     external_predict = accuracy_score(y_test, reg.predict(X_test_scale))\n",
    "\n",
    "#     print (\"External scaled CV accuracy score of {0}: {1}\".format(\n",
    "#             Model.__name__,round(external_predict,6)))\n",
    "#     print (\"Internal scaled CV accuracy score of {0}: {1}\".format(Model.__name__, round(accuracy, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 525 candidates, totalling 5250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed: 55.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 59.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1177 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1277 tasks      | elapsed: 75.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed: 78.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1381 tasks      | elapsed: 83.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 88.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1489 tasks      | elapsed: 93.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 99.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1601 tasks      | elapsed: 102.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed: 108.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1717 tasks      | elapsed: 111.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 117.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1837 tasks      | elapsed: 121.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1898 tasks      | elapsed: 127.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 423.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 429.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2089 tasks      | elapsed: 434.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2154 tasks      | elapsed: 439.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2221 tasks      | elapsed: 445.7min\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001B0D3CD1DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001B0D3CD1DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(660, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(660, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (660, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=660, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'05f372bc02734388a7d09f0f1ecebeec']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'05f372bc02734388a7d09f0f1ecebeec'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-7-945ece8e6355>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>\n        result = <ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>, result=<ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>\n        self.user_global_ns = {'Binarizer': <class 'sklearn.preprocessing.data.Binarizer'>, 'C_OPTIONS': [0.01, 0.1, 1.0, 10.0, 100.0], 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"#\\n# The 2017 Public Schools Machine Learning Dat...sets/PublicSchools2017_ML.csv', low_memory=False)\", \"#split data into X and y dataframes\\n\\nSPG_Grade_c...ool_data.filter(regex='^SPG\\\\WGrade|unit_code')))]\", '#split X and y into test and train sets.\\n\\n\\nX_tra...in, y_test = train_test_split(X, y, test_size=.2)', '# #applied a scaling procedure to scale the size...rm(X_train)\\n# X_test_scale = sc.transform(X_test)', '# #Initializing the Logistic Regression function..._scale = Log_Reg_classifier.predict(X_test_scale)', 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NMF': <class 'sklearn.decomposition.nmf.NMF'>, ...}\n        self.user_ns = {'Binarizer': <class 'sklearn.preprocessing.data.Binarizer'>, 'C_OPTIONS': [0.01, 0.1, 1.0, 10.0, 100.0], 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"#\\n# The 2017 Public Schools Machine Learning Dat...sets/PublicSchools2017_ML.csv', low_memory=False)\", \"#split data into X and y dataframes\\n\\nSPG_Grade_c...ool_data.filter(regex='^SPG\\\\WGrade|unit_code')))]\", '#split X and y into test and train sets.\\n\\n\\nX_tra...in, y_test = train_test_split(X, y, test_size=.2)', '# #applied a scaling procedure to scale the size...rm(X_train)\\n# X_test_scale = sc.transform(X_test)', '# #Initializing the Logistic Regression function..._scale = Log_Reg_classifier.predict(X_test_scale)', 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NMF': <class 'sklearn.decomposition.nmf.NMF'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Dropbox\\School\\MSDS 7331 Data Mining\\Project\\MiniLab2\\<ipython-input-7-945ece8e6355> in <module>()\n    104     \n    105 ]\n    106 \n    107 grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=10 )\n    108 \n--> 109 grid_search.fit(X_train, y_train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.KFold(n...in_score='warn',\n       scoring=None, verbose=10), X=      student_num  lea_avg_student_num  st_avg_s...                   0  \n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _CVIterableWrapper.split of _CVIte... 1953]), array([   2,    3, ..., 1938, 1949]))])>\n        X =       student_num  lea_avg_student_num  st_avg_s...                   0  \n\n[1954 rows x 327 columns]\n        y = 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jun  9 06:05:54 2018\nPID: 99076       Python 3.6.5: C:\\Users\\Steven Millett\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), X=      student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([   1,    2,    3, ..., 1951, 1952, 1953]), test=array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), verbose=10, parameters={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__C': 0.01, 'reduce_dim__n_components': 50}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.0001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.01}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.01})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.01}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.01})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 282, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 77, in set_params\n    super(BaseSGD, self).set_params(*args, **kwargs)\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jun  9 06:05:54 2018\nPID: 99076       Python 3.6.5: C:\\Users\\Steven Millett\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), X=      student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([   1,    2,    3, ..., 1951, 1952, 1953]), test=array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), verbose=10, parameters={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__C': 0.01, 'reduce_dim__n_components': 50}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.0001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.01}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.01})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.01}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.01})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Jun  9 06:05:54 2018\nPID: 99076       Python 3.6.5: C:\\Users\\Steven Millett\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), X=      student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([   1,    2,    3, ..., 1951, 1952, 1953]), test=array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), verbose=10, parameters={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__C': 0.01, 'reduce_dim__n_components': 50}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.0001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.01}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.01})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.01}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.01})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-945ece8e6355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001B0D3CD1DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001B0D3CD1DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(660, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(660, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (660, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=660, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'05f372bc02734388a7d09f0f1ecebeec']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'05f372bc02734388a7d09f0f1ecebeec'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 9, 5, 37, 2, 508017, tzinfo=tzutc()), 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'session': '05f372bc02734388a7d09f0f1ecebeec', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'bcd8bf249ffa42e38cbfec2d13505c80', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-7-945ece8e6355>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>\n        result = <ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>, result=<ExecutionResult object at 1b0d605ea90, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001B0F0EEDED0, file \"<ipython-input-7-945ece8e6355>\", line 109>\n        self.user_global_ns = {'Binarizer': <class 'sklearn.preprocessing.data.Binarizer'>, 'C_OPTIONS': [0.01, 0.1, 1.0, 10.0, 100.0], 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"#\\n# The 2017 Public Schools Machine Learning Dat...sets/PublicSchools2017_ML.csv', low_memory=False)\", \"#split data into X and y dataframes\\n\\nSPG_Grade_c...ool_data.filter(regex='^SPG\\\\WGrade|unit_code')))]\", '#split X and y into test and train sets.\\n\\n\\nX_tra...in, y_test = train_test_split(X, y, test_size=.2)', '# #applied a scaling procedure to scale the size...rm(X_train)\\n# X_test_scale = sc.transform(X_test)', '# #Initializing the Logistic Regression function..._scale = Log_Reg_classifier.predict(X_test_scale)', 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NMF': <class 'sklearn.decomposition.nmf.NMF'>, ...}\n        self.user_ns = {'Binarizer': <class 'sklearn.preprocessing.data.Binarizer'>, 'C_OPTIONS': [0.01, 0.1, 1.0, 10.0, 100.0], 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HTML': <class 'IPython.core.display.HTML'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma..._ipython().run_line_magic('matplotlib', 'inline')\", \"#\\n# The 2017 Public Schools Machine Learning Dat...sets/PublicSchools2017_ML.csv', low_memory=False)\", \"#split data into X and y dataframes\\n\\nSPG_Grade_c...ool_data.filter(regex='^SPG\\\\WGrade|unit_code')))]\", '#split X and y into test and train sets.\\n\\n\\nX_tra...in, y_test = train_test_split(X, y, test_size=.2)', '# #applied a scaling procedure to scale the size...rm(X_train)\\n# X_test_scale = sc.transform(X_test)', '# #Initializing the Logistic Regression function..._scale = Log_Reg_classifier.predict(X_test_scale)', 'k_fold = KFold(len(y_train),n_folds=10,shuffle=T..., verbose=10 )\\n\\ngrid_search.fit(X_train, y_train)'], 'KFold': <class 'sklearn.cross_validation.KFold'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'NMF': <class 'sklearn.decomposition.nmf.NMF'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Steven Millett\\Dropbox\\School\\MSDS 7331 Data Mining\\Project\\MiniLab2\\<ipython-input-7-945ece8e6355> in <module>()\n    104     \n    105 ]\n    106 \n    107 grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=10 )\n    108 \n--> 109 grid_search.fit(X_train, y_train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.KFold(n...in_score='warn',\n       scoring=None, verbose=10), X=      student_num  lea_avg_student_num  st_avg_s...                   0  \n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method _CVIterableWrapper.split of _CVIte... 1953]), array([   2,    3, ..., 1938, 1949]))])>\n        X =       student_num  lea_avg_student_num  st_avg_s...                   0  \n\n[1954 rows x 327 columns]\n        y = 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Jun  9 06:05:54 2018\nPID: 99076       Python 3.6.5: C:\\Users\\Steven Millett\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]),       student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], 1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, {'score': <function _passthrough_scorer>}, array([   1,    2,    3, ..., 1951, 1952, 1953]), array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), 10, {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), X=      student_num  lea_avg_student_num          ...                     0\n\n[1954 rows x 327 columns], y=1631    C\n297     C\n2206    C\n55      F\n2006    ...B\n1586    D\n2286    C\nLength: 1954, dtype: object, scorer={'score': <function _passthrough_scorer>}, train=array([   1,    2,    3, ..., 1951, 1952, 1953]), test=array([   0,   16,   33,   38,   42,   69,   74,... 1896, 1899, 1903, 1911, 1934, 1941, 1948, 1950]), verbose=10, parameters={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__C': 0.01, 'reduce_dim': NMF(alpha=0.0, beta_loss='frobenius', init=None,...ffle=False, solver='cd',\n  tol=0.0001, verbose=0), 'reduce_dim__n_components': 50, 'scale': None}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'clf__C': 0.01, 'reduce_dim__n_components': 50}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('reduce_dim',...e=True, tol=None, verbose=0, warm_start=False))]), **params={'clf__C': 0.01, 'reduce_dim__n_components': 50})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'clf': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'clf__alpha': 0.0001, 'clf__average': False, 'clf__class_weight': None, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.01}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.01})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.01}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\Steven Millett\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.01})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(len(y_train),n_folds=10,shuffle=True)\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', NMF()),\n",
    "                 ('scale', StandardScaler()), \n",
    "                 ('clf', LogisticRegression())])\n",
    "\n",
    "N_FEATURES_OPTIONS = [50, 100, 150]\n",
    "C_OPTIONS = [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [None],\n",
    "        'scale':[None],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [None],\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [None],\n",
    "        'scale':[None],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__alpha': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [None],\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__alpha': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'scale':[None],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'scale':[None],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__alpha': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'scale':[None],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SVC(),LogisticRegression()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'scale':[None],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'scale':[StandardScaler()],\n",
    "        'clf':[SGDClassifier()],\n",
    "        'scale__with_mean':[True,False],\n",
    "        'scale__with_std':[True,False],\n",
    "        'clf__tol': [1e-3],\n",
    "        'clf__max_iter':[1000],\n",
    "        'clf__alpha': C_OPTIONS\n",
    "    },\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=k_fold,n_jobs=-1, verbose=2 )\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid_search, 'savedBestModel.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "grid_search = joblib.load('savedBestModel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19e9d7bc160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_labels=['SVM','LogisticRegression','SGDClassifier']\n",
    "mean_scores = np.array(grid_search.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(N_FEATURES_OPTIONS), -1, len(C_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(C_OPTIONS)) *\n",
    "               (len(classifier_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, class_scores) in enumerate(zip(classifier_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, class_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(classifier_labels) / 2, C_OPTIONS)\n",
    "plt.ylabel('Digit classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "{'clf': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'clf__C': 1.0, 'scale': StandardScaler(copy=True, with_mean=True, with_std=True), 'scale__with_mean': True, 'scale__with_std': True}\n",
      "0.8336745138178097\n"
     ]
    }
   ],
   "source": [
    "#print(grid_search.best_estimator_)\n",
    "print(grid_search.best_index_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Advantages\n",
    "Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the accuracy of the two models there are a couple of obvious observations.\n",
    "\n",
    "1. SVM is negatively to non-standardized observations.\n",
    "2. Logistic Regression ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Feature Importance\n",
    "Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Support Vectors\n",
    "Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
